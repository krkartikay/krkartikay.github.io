<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>2. Initial plan</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/584705cbbef33b49.css" as="style"/><link rel="stylesheet" href="/_next/static/css/584705cbbef33b49.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-83cebdb887f48834.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb98586f475796ed.js" defer=""></script><script src="/_next/static/chunks/247-fb3f3c148c859656.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bnote_id%5D-774c61eb2a4693cc.js" defer=""></script><script src="/_next/static/YSBOv2XcBuOnYCm6VLvJs/_buildManifest.js" defer=""></script><script src="/_next/static/YSBOv2XcBuOnYCm6VLvJs/_ssgManifest.js" defer=""></script></head><body class="dark:bg-black dark:bg-opacity-95"><div id="__next"><div><nav class="md:sticky md:top-0 md:z-40 shadow-sm p-2 bg-white dark:bg-black dark:shadow-lg dark:shadow-stone-800"><div class="flex items-center"><a class="flex" href="/"><img alt="Profile pic" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="rounded-full h-20 w-20 mx-2" style="color:transparent" src="/pfp_blank.png"/><h1 class="self-center text-xl text-stone-400 font-mono dark:text-stone-50 dark:drop-shadow-2xl dark:shadow-white dark:hover:text-stone-200">krkartikay&#x27;s notes</h1></a></div></nav><div class="flex flex-row flex-wrap"><aside class="md:w-1/4 text-stone-500 dark:text-stone-200"><div class="max-w-md mx-auto py-8"><a href="/"><h2 class="p-8 text-lg text-stone-600 hover:bg-stone-100 dark:text-stone-200 dark:hover:bg-stone-800 dark:hover:text-stone-200 ">Notes</h2></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Book Notes</li></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__if"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">&quot;If&quot;</li></a><a href="/notes/book%20notes__dokkodo"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Dokkodo</li></a><a href="/notes/book%20notes__the%20bhagvad%20gita__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">The Bhagvad Gita</li></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__the%20bhagvad%20gita__chapter_1"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Chapter 1</li></a><a href="/notes/book%20notes__the%20bhagvad%20gita__chapter_2"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Chapter 2</li></a></ul><a href="/notes/book%20notes__worry"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Worry</li></a></ul><a href="/notes/economics__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Economics</li></a><ul class="list-disc pl-8"><a href="/notes/economics__microeconomics__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Microeconomics</li></a><ul class="list-disc pl-8"><a href="/notes/economics__microeconomics__lecture_1"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 1</li></a><a href="/notes/economics__microeconomics__lecture_2"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 2</li></a><a href="/notes/economics__microeconomics__lecture_3"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 3</li></a><a href="/notes/economics__microeconomics__lecture_4"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 4</li></a><a href="/notes/economics__microeconomics__lecture_5"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 5</li></a><a href="/notes/economics__microeconomics__lecture_6"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 6</li></a></ul></ul><a href="/notes/machine%20learning__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Machine Learning</li></a><ul class="list-disc pl-8"><a href="/notes/machine%20learning__alpha%20zero__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Alpha Zero</li></a><ul class="list-disc pl-8"><a href="/notes/machine%20learning__alpha%20zero__1-the-start"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">1. The Start</li></a><a href="/notes/machine%20learning__alpha%20zero__2-initial-plan"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside font-bold bg-stone-50 dark:bg-stone-800">2. Initial plan</li></a><a href="/notes/machine%20learning__alpha%20zero__3-supervised-learning"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">3. Supervised Learning</li></a><a href="/notes/machine%20learning__alpha%20zero___notes"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">_notes</li></a></ul><a href="/notes/machine%20learning__karpathy-lectures"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Andrey Karpathy&#x27;s Lectures</li></a><a href="/notes/machine%20learning__study-plan"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">ML Study plan</li></a><a href="/notes/machine%20learning__cpp-grad"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">cpp-grad</li></a></ul><a href="/notes/quotes"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Quotes</li></a></ul></div></aside><main class="md:w-3/4 border-l-2 dark:border-l-stone-900 border-l-stone-50"><div class="p-8 md:p-16"><br/><h1 class="text-4xl dark:text-white">2. Initial plan</h1><p class="text-stone-400 dark:text-stone-300">2024-01-14</p><div class="prose prose-stone dark:prose-invert"><div><h2>Initial Plan</h2>
<p>Let's create a new repository... <a href="https://github.com/krkartikay/chess-sl">done</a>!</p>
<p>Okay here's the plan. We'll start with doing supervised learning only.
That too on self-generated data. Once we have a neural net that has
at least learnt <em>the rules of chess</em> we'll go ahead and try reinforcement
learning using MCTS.</p>
<ol>
<li>Create a new repository.</li>
<li>Install pytorch etc., whatever is required.</li>
<li>Create the most basic supervised learning model possible.</li>
<li>Create an experimentation framework.</li>
<li>Create a framework for visualisation of the model and data.</li>
</ol>
<p>The real question is... How?</p>
<p>What do I mean by experimentation and observability framework?</p>
<p>A few ideas:</p>
<ol>
<li>imagine I have a dashboard where I can adjust hyperparams,
click buttons to start/stop training runs, it shows graphs etc.</li>
<li>imagine I have a config file where I can specify a few
different values of hyperparameters and the thing runs
experiments in the background and stores the results
in appropriate files (which we can compare in the above dashboard later)</li>
<li>imagine I have a tool to analyse the training data and the
model's output distributions on an actual chessboard visualisation.
Like drawing arrows on the chessboard, showing probs, etc.</li>
</ol>
<p>From previous experience, it would be better to develop different tools in a modular way.</p>
<p>So we could go about it in this order:</p>
<ol>
<li>Python framework to run the experiments and store results.</li>
<li>Dashboard to visualise results.</li>
<li>Dashboard to control hyperparams and run training scripts.</li>
<li>Dashboard for chess data and model analysis.</li>
</ol>
<p>Once (1) is done, it would be much easier to develop the dashboards (2) and (3)!
We could use something standard like Sqlite for (1) and maybe flask or streamlit or something
for (2) and (3). (4) is a bit uncertain, but probably the best way to go about it
would be starting with llichess's chess board modules.</p>
<h2>Problem specification</h2>
<p>There are some choices we need to make while modeling the problem itself.
What exactly is it that we're trying to do first?</p>
<p>I was trying last time to just get a neural net to <em>learn the rules of chess</em>,
that is, by being shown a lot of games, just predict which moves are allowed and which ones
are not.</p>
<p>I just realised last night that this task can become much more simpler for the neural net
depending on the action space encoding.</p>
<p>In particular what I was trying to do last time was to make the network predict the probability
distribution of valid moves, with the action space being <code>(from square, to square)</code>, that is,
<code>64*64</code> actions.</p>
<p>However I realised most of the neurons which would have to predict the probabilities
would ideally have to always output <code>0</code>. Why? Because for every <code>from square</code>, only certain
<code>to squares</code> could ever be valid moves.</p>
<p>In particular, for every <code>from</code> square we would have an upper bound of
<code>7(hz) + 7(vt) + 7(dg)(max) + 7(dg)(max) + 8(kn)(max) = 36</code> possible <code>to</code>
squares. That means the real size of the action space should be closer to
<code>36*64=2304</code> instead of <code>64*64=4096</code> (not considering underpromotions).</p>
<p>Also Leela Chess Zero has an action space size of <code>1858</code> which they say
they gather from an <code>73*8*8</code> matrix using a certain mapping. Where did
they get <code>1858</code> from!?</p>
<p>Anyway, back to the original question. Let's actually try to do the same thing as last time.
We'll predict the <code>64*64</code> probabilities for <code>(from square, to square)</code>.
(We'll ignore underpromotion for now).</p>
<p>(*note to myself: keep in mind bugs related to underpromotion and castling.)</p>
<p>This would be a real test of <em>generalisation</em>. Is our network able to learn
<em>the rules of chess</em> or does it simply memorise the training data?</p>
<h3>Output?</h3>
<p>What should the model output?</p>
<p>Last time I used KL-divergence loss to make the net predict a probability distribution for
all the moves, but I wonder if a per-move probability is better. In one experiment I had
found that a per-move probability is probably much easier to train as there is no dependence on
other moves. However should it really be this way? TODO: think about this more later.</p>
<p>For now let's make it do the latter. That is, we will have 64*64 per-move probabilities.
(ideally many of which should always be 0 after training).</p>
<h3>Let's go!</h3>
<p>Okay we're all set for now, LESGOOO!</p></div></div></div></main></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note_id":"machine learning__alpha zero__2-initial-plan","noteData":{"metadata":{"title":"2. Initial plan","date":"2024-01-14"},"content":"\u003ch2\u003eInitial Plan\u003c/h2\u003e\n\u003cp\u003eLet's create a new repository... \u003ca href=\"https://github.com/krkartikay/chess-sl\"\u003edone\u003c/a\u003e!\u003c/p\u003e\n\u003cp\u003eOkay here's the plan. We'll start with doing supervised learning only.\nThat too on self-generated data. Once we have a neural net that has\nat least learnt \u003cem\u003ethe rules of chess\u003c/em\u003e we'll go ahead and try reinforcement\nlearning using MCTS.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCreate a new repository.\u003c/li\u003e\n\u003cli\u003eInstall pytorch etc., whatever is required.\u003c/li\u003e\n\u003cli\u003eCreate the most basic supervised learning model possible.\u003c/li\u003e\n\u003cli\u003eCreate an experimentation framework.\u003c/li\u003e\n\u003cli\u003eCreate a framework for visualisation of the model and data.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThe real question is... How?\u003c/p\u003e\n\u003cp\u003eWhat do I mean by experimentation and observability framework?\u003c/p\u003e\n\u003cp\u003eA few ideas:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eimagine I have a dashboard where I can adjust hyperparams,\nclick buttons to start/stop training runs, it shows graphs etc.\u003c/li\u003e\n\u003cli\u003eimagine I have a config file where I can specify a few\ndifferent values of hyperparameters and the thing runs\nexperiments in the background and stores the results\nin appropriate files (which we can compare in the above dashboard later)\u003c/li\u003e\n\u003cli\u003eimagine I have a tool to analyse the training data and the\nmodel's output distributions on an actual chessboard visualisation.\nLike drawing arrows on the chessboard, showing probs, etc.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eFrom previous experience, it would be better to develop different tools in a modular way.\u003c/p\u003e\n\u003cp\u003eSo we could go about it in this order:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePython framework to run the experiments and store results.\u003c/li\u003e\n\u003cli\u003eDashboard to visualise results.\u003c/li\u003e\n\u003cli\u003eDashboard to control hyperparams and run training scripts.\u003c/li\u003e\n\u003cli\u003eDashboard for chess data and model analysis.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOnce (1) is done, it would be much easier to develop the dashboards (2) and (3)!\nWe could use something standard like Sqlite for (1) and maybe flask or streamlit or something\nfor (2) and (3). (4) is a bit uncertain, but probably the best way to go about it\nwould be starting with llichess's chess board modules.\u003c/p\u003e\n\u003ch2\u003eProblem specification\u003c/h2\u003e\n\u003cp\u003eThere are some choices we need to make while modeling the problem itself.\nWhat exactly is it that we're trying to do first?\u003c/p\u003e\n\u003cp\u003eI was trying last time to just get a neural net to \u003cem\u003elearn the rules of chess\u003c/em\u003e,\nthat is, by being shown a lot of games, just predict which moves are allowed and which ones\nare not.\u003c/p\u003e\n\u003cp\u003eI just realised last night that this task can become much more simpler for the neural net\ndepending on the action space encoding.\u003c/p\u003e\n\u003cp\u003eIn particular what I was trying to do last time was to make the network predict the probability\ndistribution of valid moves, with the action space being \u003ccode\u003e(from square, to square)\u003c/code\u003e, that is,\n\u003ccode\u003e64*64\u003c/code\u003e actions.\u003c/p\u003e\n\u003cp\u003eHowever I realised most of the neurons which would have to predict the probabilities\nwould ideally have to always output \u003ccode\u003e0\u003c/code\u003e. Why? Because for every \u003ccode\u003efrom square\u003c/code\u003e, only certain\n\u003ccode\u003eto squares\u003c/code\u003e could ever be valid moves.\u003c/p\u003e\n\u003cp\u003eIn particular, for every \u003ccode\u003efrom\u003c/code\u003e square we would have an upper bound of\n\u003ccode\u003e7(hz) + 7(vt) + 7(dg)(max) + 7(dg)(max) + 8(kn)(max) = 36\u003c/code\u003e possible \u003ccode\u003eto\u003c/code\u003e\nsquares. That means the real size of the action space should be closer to\n\u003ccode\u003e36*64=2304\u003c/code\u003e instead of \u003ccode\u003e64*64=4096\u003c/code\u003e (not considering underpromotions).\u003c/p\u003e\n\u003cp\u003eAlso Leela Chess Zero has an action space size of \u003ccode\u003e1858\u003c/code\u003e which they say\nthey gather from an \u003ccode\u003e73*8*8\u003c/code\u003e matrix using a certain mapping. Where did\nthey get \u003ccode\u003e1858\u003c/code\u003e from!?\u003c/p\u003e\n\u003cp\u003eAnyway, back to the original question. Let's actually try to do the same thing as last time.\nWe'll predict the \u003ccode\u003e64*64\u003c/code\u003e probabilities for \u003ccode\u003e(from square, to square)\u003c/code\u003e.\n(We'll ignore underpromotion for now).\u003c/p\u003e\n\u003cp\u003e(*note to myself: keep in mind bugs related to underpromotion and castling.)\u003c/p\u003e\n\u003cp\u003eThis would be a real test of \u003cem\u003egeneralisation\u003c/em\u003e. Is our network able to learn\n\u003cem\u003ethe rules of chess\u003c/em\u003e or does it simply memorise the training data?\u003c/p\u003e\n\u003ch3\u003eOutput?\u003c/h3\u003e\n\u003cp\u003eWhat should the model output?\u003c/p\u003e\n\u003cp\u003eLast time I used KL-divergence loss to make the net predict a probability distribution for\nall the moves, but I wonder if a per-move probability is better. In one experiment I had\nfound that a per-move probability is probably much easier to train as there is no dependence on\nother moves. However should it really be this way? TODO: think about this more later.\u003c/p\u003e\n\u003cp\u003eFor now let's make it do the latter. That is, we will have 64*64 per-move probabilities.\n(ideally many of which should always be 0 after training).\u003c/p\u003e\n\u003ch3\u003eLet's go!\u003c/h3\u003e\n\u003cp\u003eOkay we're all set for now, LESGOOO!\u003c/p\u003e"},"allNotesIndex":{"base_name":"notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes","notes_data":[{"id":"quotes","metadata":{"title":"Quotes","date":"2023-03-21"}}],"directories":[{"base_name":"book notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes","notes_data":[{"id":"dokkodo","metadata":{"title":"Dokkodo","date":"2023-03-23"}},{"id":"if","metadata":{"title":"\"If\"","date":"2023-03-27"}},{"id":"worry","metadata":{"title":"Worry","date":"2023-03-29"}}],"directories":[{"base_name":"the bhagvad gita","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes/the bhagvad gita","notes_data":[{"id":"chapter_1","metadata":{"title":"Chapter 1","date":"2023-04-06"}},{"id":"chapter_2","metadata":{"title":"Chapter 2","date":"2023-04-08"}},{"id":"index","metadata":{"title":"The Bhagvad Gita","date":"2023-04-06"}}],"directories":[]}]},{"base_name":"economics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics","notes_data":[],"directories":[{"base_name":"microeconomics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics/microeconomics","notes_data":[{"id":"index","metadata":{"title":"Principles of Microeconomics","date":"2023-03-23"}},{"id":"lecture_1","metadata":{"title":"Lecture 1","date":"2023-03-23"}},{"id":"lecture_2","metadata":{"title":"Lecture 2","date":"2023-03-23"}},{"id":"lecture_3","metadata":{"title":"Lecture 3","date":"2023-03-23"}},{"id":"lecture_4","metadata":{"title":"Lecture 4","date":"2023-04-01"}},{"id":"lecture_5","metadata":{"title":"Lecture 5","date":"2023-04-01"}},{"id":"lecture_6","metadata":{"title":"Lecture 6","date":"2023-04-01"}}],"directories":[]}]},{"base_name":"machine learning","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning","notes_data":[{"id":"cpp-grad","metadata":{"title":"cpp-grad","date":"2023-04-17"}},{"id":"karpathy-lectures","metadata":{"title":"Andrey Karpathy's Lectures","date":"2023-05-14"}},{"id":"study-plan","metadata":{"title":"ML Study plan","date":"2024-01-14"}}],"directories":[{"base_name":"alpha zero","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning/alpha zero","notes_data":[{"id":"1-the-start","metadata":{"title":"1. The Start","date":"2024-01-14"}},{"id":"2-initial-plan","metadata":{"title":"2. Initial plan","date":"2024-01-14"}},{"id":"3-supervised-learning","metadata":{"title":"3. Supervised Learning","date":"2024-01-15"}},{"id":"_notes","metadata":{"title":"_notes"}}],"directories":[]}]}]}},"__N_SSG":true},"page":"/notes/[note_id]","query":{"note_id":"machine learning__alpha zero__2-initial-plan"},"buildId":"YSBOv2XcBuOnYCm6VLvJs","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>