<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>3. Supervised Learning</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/584705cbbef33b49.css" as="style"/><link rel="stylesheet" href="/_next/static/css/584705cbbef33b49.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-83cebdb887f48834.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb98586f475796ed.js" defer=""></script><script src="/_next/static/chunks/247-fb3f3c148c859656.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bnote_id%5D-774c61eb2a4693cc.js" defer=""></script><script src="/_next/static/qT0P1lb5TYCjTWSp0uAq_/_buildManifest.js" defer=""></script><script src="/_next/static/qT0P1lb5TYCjTWSp0uAq_/_ssgManifest.js" defer=""></script></head><body class="dark:bg-black dark:bg-opacity-95"><div id="__next"><div><nav class="md:sticky md:top-0 md:z-40 shadow-sm p-2 bg-white dark:bg-black dark:shadow-lg dark:shadow-stone-800"><div class="flex items-center"><a class="flex" href="/"><img alt="Profile pic" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="rounded-full h-20 w-20 mx-2" style="color:transparent" src="/pfp_blank.png"/><h1 class="self-center text-xl text-stone-400 font-mono dark:text-stone-50 dark:drop-shadow-2xl dark:shadow-white dark:hover:text-stone-200">krkartikay&#x27;s notes</h1></a></div></nav><div class="flex flex-row flex-wrap"><aside class="md:w-1/4 text-stone-500 dark:text-stone-200"><div class="max-w-md mx-auto py-8"><a href="/"><h2 class="p-8 text-lg text-stone-600 hover:bg-stone-100 dark:text-stone-200 dark:hover:bg-stone-800 dark:hover:text-stone-200 ">Notes</h2></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Book Notes</li></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__if"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">&quot;If&quot;</li></a><a href="/notes/book%20notes__dokkodo"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Dokkodo</li></a><a href="/notes/book%20notes__the%20bhagvad%20gita__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">The Bhagvad Gita</li></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__the%20bhagvad%20gita__chapter_1"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Chapter 1</li></a><a href="/notes/book%20notes__the%20bhagvad%20gita__chapter_2"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Chapter 2</li></a></ul><a href="/notes/book%20notes__worry"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Worry</li></a></ul><a href="/notes/economics__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Economics</li></a><ul class="list-disc pl-8"><a href="/notes/economics__microeconomics__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Microeconomics</li></a><ul class="list-disc pl-8"><a href="/notes/economics__microeconomics__lecture_1"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 1</li></a><a href="/notes/economics__microeconomics__lecture_2"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 2</li></a><a href="/notes/economics__microeconomics__lecture_3"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 3</li></a><a href="/notes/economics__microeconomics__lecture_4"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 4</li></a><a href="/notes/economics__microeconomics__lecture_5"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 5</li></a><a href="/notes/economics__microeconomics__lecture_6"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 6</li></a></ul></ul><a href="/notes/machine%20learning__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Machine Learning</li></a><ul class="list-disc pl-8"><a href="/notes/machine%20learning__alpha%20zero__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Alpha Zero</li></a><ul class="list-disc pl-8"><a href="/notes/machine%20learning__alpha%20zero__1-the-start"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">1. The Start</li></a><a href="/notes/machine%20learning__alpha%20zero__2-initial-plan"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">2. Initial plan</li></a><a href="/notes/machine%20learning__alpha%20zero__3-supervised-learning"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside font-bold bg-stone-50 dark:bg-stone-800">3. Supervised Learning</li></a><a href="/notes/machine%20learning__alpha%20zero__4-experimentation"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">4. Experimentation Framework</li></a><a href="/notes/machine%20learning__alpha%20zero__5-visualization"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">5. Visualization</li></a><a href="/notes/machine%20learning__alpha%20zero___notes"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">_notes</li></a></ul><a href="/notes/machine%20learning__karpathy-lectures"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Andrey Karpathy&#x27;s Lectures</li></a><a href="/notes/machine%20learning__study-plan"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">ML Study plan</li></a><a href="/notes/machine%20learning__cpp-grad"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">cpp-grad</li></a></ul><a href="/notes/quotes"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Quotes</li></a></ul></div></aside><main class="md:w-3/4 border-l-2 dark:border-l-stone-900 border-l-stone-50"><div class="p-8 md:p-16"><br/><h1 class="text-4xl dark:text-white">3. Supervised Learning</h1><p class="text-stone-400 dark:text-stone-300">2024-01-15</p><div class="prose prose-stone dark:prose-invert"><div><h3>First update!</h3>
<p>I've got supervised learning to kinda work!</p>
<p>I've been able to generate a dataset consisting of lots of random positions and
the allowed moves in all those positions. Then I've been able to read that data
and train neural networks on it which learn the rules of chess reasonably well.</p>
<p>I'm implementing it again (cleanly) <a href="https://github.com/krkartikay/chess-sl">in this repo</a>
and also documenting whatever I'm doing here.</p>
<h3>Generating the dataset</h3>
<p>First we will need to generate the dataset consisting of randomly generated
positions and the allowed move in each position. This can be done using the
<code>chess</code> python library.</p>
<p><a href="https://github.com/krkartikay/chess-sl/blob/main/gen_moves.py">gen_moves.py</a></p>
<pre><code class="hljs language-py"><span class="hljs-keyword">import</span> chess
<span class="hljs-keyword">import</span> random

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_random_game</span>():
    board = chess.Board()
    history = []
    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> board.is_game_over():
        <span class="hljs-comment"># print(board)</span>
        valid_moves = <span class="hljs-built_in">list</span>(board.generate_legal_moves())
        <span class="hljs-comment"># print(valid_moves)</span>
        random_move = random.choice(valid_moves)
        history.append((board, valid_moves))
        board.push(random_move)
    <span class="hljs-keyword">return</span> history
</code></pre>
<p>Then we need to store the generated data. Now we could serialise it into any
format. Games are generally stored in PGN format and we could find some format
for our moves too but since we're going to train neural networks using this data
so it may be best to convert these to tensors already and store them in a tensor
format.</p>
<p>So far the code is pretty fast, taking only ~2s to generate 100 games.</p>
<pre><code>$ time python gen_moves.py 
Generating game 1.
Generating game 2.
Generating game 3.
...
Generating game 100.
Done! Generated 100 games!

real    0m2.396s
user    0m2.282s
sys     0m0.111s
</code></pre>
<h3>Converting to tensors</h3>
<p>There are many possible ways we could do this, but I'm going to encode the 6
piece types (Pawn, Rook, Knight, etc.) into different planes into a tensor.
I'm going to use +1 for the white pieces and -1 for the black pieces.
I'm also going to add another plane which is entirely +1 or -1 denoting whose
turn it is currently.</p>
<p>This is what the starting board is supposed to look like, as a tensor (White = +1
Black = -1, Gray = 0).</p>
<p><img src="/notes/start-position.png" alt="starting position tensor"></p>
<p>Here's the code:</p>
<p><a href="https://github.com/krkartikay/chess-sl/blob/main/chess_utils.py">chess_utils.py</a></p>
<pre><code class="hljs language-py"><span class="hljs-keyword">import</span> chess
<span class="hljs-keyword">import</span> torch


<span class="hljs-keyword">def</span> <span class="hljs-title function_">board_to_tensor</span>(<span class="hljs-params">board: chess.Board</span>) -> torch.Tensor:
    return_tensor = torch.zeros((<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>))
    <span class="hljs-comment"># Iterate over the 6 piece types and add them to the appropriate plane</span>
    <span class="hljs-comment"># in the return tensor.</span>
    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">7</span>):
        pt = chess.PieceType(layer)
        <span class="hljs-comment"># add +1 for all the white pieces and -1 for black pieces</span>
        bitboard_white = board.pieces_mask(pt, chess.WHITE)
        bitboard_black = board.pieces_mask(pt, chess.BLACK)
        <span class="hljs-keyword">for</span> sq <span class="hljs-keyword">in</span> chess.SQUARES:
            <span class="hljs-keyword">if</span> bitboard_white &#x26; (<span class="hljs-number">1</span> &#x3C;&#x3C; sq):
                row, col = <span class="hljs-built_in">divmod</span>(sq, <span class="hljs-number">8</span>)
                return_tensor[layer, row, col] += <span class="hljs-number">1</span>
            <span class="hljs-keyword">if</span> bitboard_black &#x26; (<span class="hljs-number">1</span> &#x3C;&#x3C; sq):
                row, col = <span class="hljs-built_in">divmod</span>(sq, <span class="hljs-number">8</span>)
                return_tensor[layer, row, col] -= <span class="hljs-number">1</span>
        <span class="hljs-comment"># fill in the last layer according with +/- 1 based on whose turn it is</span>
        <span class="hljs-keyword">if</span> board.turn == chess.WHITE:
            return_tensor[<span class="hljs-number">0</span>, :, :] += <span class="hljs-number">1</span>
        <span class="hljs-keyword">else</span>:
            return_tensor[<span class="hljs-number">0</span>, :, :] -= <span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> return_tensor
</code></pre>
<p>Simply calling this function in <code>main()</code> on every position we have so far
increases the running time of the script to around ~5-6 seconds.</p>
<p>I'm also writing unit tests this time... it helped me catch a bug already!
(Do you see what was wrong in the code above? Hehe...)</p>
<p><a href="https://github.com/krkartikay/chess-sl/blob/main/chess_utils_test.py">chess_utils_test.py</a></p>
<pre><code class="hljs language-py"><span class="hljs-keyword">import</span> chess
<span class="hljs-keyword">import</span> chess_utils


<span class="hljs-keyword">def</span> <span class="hljs-title function_">test_board_to_tensor</span>():
    board = chess.Board()
    tensor = chess_utils.board_to_tensor(board)
    <span class="hljs-built_in">print</span>(tensor)

    <span class="hljs-comment"># tensor has correct shape</span>
    <span class="hljs-keyword">assert</span> tensor.size() == (<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>)

    <span class="hljs-comment"># first turn is white</span>
    <span class="hljs-keyword">assert</span> tensor[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>] == <span class="hljs-number">1</span>

    <span class="hljs-comment"># board has equal number of pieces at the start</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">7</span>):
        <span class="hljs-keyword">assert</span> tensor[i].<span class="hljs-built_in">sum</span>() == <span class="hljs-number">0</span>
</code></pre>
<pre><code>$ pytest
=========================== test session starts ============================
platform linux -- Python 3.11.4, pytest-7.4.0, pluggy-1.0.0
rootdir: /home/krkartikay/code/chess-sl
plugins: hydra-core-1.3.2, anyio-3.7.1
collected 1 item                                                           

chess_utils_test.py F                                                [100%]

================================= FAILURES =================================
___________________________ test_board_to_tensor ___________________________

    def test_board_to_tensor():
        board = chess.Board()
        tensor = chess_utils.board_to_tensor(board)
    
        # tensor has correct shape
        assert tensor.size() == (7, 8, 8)
    
        # first turn is white
>       assert tensor[0, 0, 0] == 1
E       assert tensor(6.) == 1

chess_utils_test.py:13: AssertionError
========================= short test summary info ==========================
FAILED chess_utils_test.py::test_board_to_tensor - assert tensor(6.) == 1
============================ 1 failed in 0.76s =============================
</code></pre>
<h3>Encoding moves</h3>
<p>Another big decision to make here is how to encode and decode the moves.
As I discussed last time, certain encodings make it easier or harder for the
neural net to learn.</p>
<p>For now I'm going to use a kind of <code>(from sq, to sq)</code> encoding.</p>
<p>Here are my conversion functions:</p>
<p><a href="https://github.com/krkartikay/chess-sl/blob/main/chess_utils.py">chess_utils.py</a></p>
<pre><code class="hljs language-py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">move_to_action</span>(<span class="hljs-params">move: chess.Move</span>) -> <span class="hljs-built_in">int</span>:
    a = move.from_square
    b = move.to_square
    idx = (a * <span class="hljs-number">64</span>) + b
    <span class="hljs-keyword">return</span> idx


<span class="hljs-keyword">def</span> <span class="hljs-title function_">action_to_move</span>(<span class="hljs-params">action: <span class="hljs-built_in">int</span>, board: chess.Board</span>) -> chess.Move:
    a, b = <span class="hljs-built_in">divmod</span>(action, <span class="hljs-number">64</span>)
    move = chess.Move(a, b)

    <span class="hljs-comment"># check for possible promotion</span>
    <span class="hljs-keyword">if</span> (chess.square_rank(b) == (<span class="hljs-number">7</span> <span class="hljs-keyword">if</span> board.turn == chess.WHITE <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)
            <span class="hljs-keyword">and</span> board.piece_type_at(a) == chess.PAWN):
        move = chess.Move(a, b, chess.QUEEN)

    <span class="hljs-keyword">return</span> move
</code></pre>
<p>Tested these via round trip encoding-decoding unit tests. Promotion works but
only to queen. We're gonna be ignoring underpromotion for now. It'll complicate
the action space architecture.</p>
<p>Okay, now we just convert all the games to tensors and save them to a file.</p>
<pre><code class="hljs language-py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_to_tensors</span>(<span class="hljs-params">
        games: <span class="hljs-type">List</span>[<span class="hljs-type">Tuple</span>[chess.Board, <span class="hljs-type">List</span>[chess.Move]]]</span>) -> torch.Tensor:
    all_positions = []
    all_valid_moves = []
    <span class="hljs-keyword">for</span> game <span class="hljs-keyword">in</span> games:
        <span class="hljs-keyword">for</span> position, valid_moves <span class="hljs-keyword">in</span> game:
            board_tensor = board_to_tensor(position)
            moves_tensor = moves_to_tensor(valid_moves)
            all_positions.append(board_tensor)
            all_valid_moves.append(moves_tensor)
    positions = torch.stack(all_positions)
    valid_moves = torch.stack(all_valid_moves)
    <span class="hljs-keyword">return</span> positions, valid_moves


<span class="hljs-keyword">def</span> <span class="hljs-title function_">save_to_file</span>(<span class="hljs-params">positions, moves, filename=<span class="hljs-string">'games.pth'</span></span>):
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> datafile:
        torch.save({<span class="hljs-string">"positions"</span>: positions, <span class="hljs-string">"moves"</span>: moves}, datafile)
</code></pre>
<p>And it works.  (Link to code so far at <a href="https://github.com/krkartikay/chess-sl/tree/d5135642685c8b43e4ebd000319a94206cee2771">commit <code>d513564</code></a>.)</p>
<pre><code>$ time python gen_moves.py 
Generating game 1.
Generating game 2.
Generating game 3.
...
Generating game 100.
Done! Generated 100 games!
Converting data to tensors.
Saving to output file.

real    0m5.955s
user    0m5.743s
sys     0m0.190s
</code></pre>
<h3>Creating a neural net!</h3>
<p>Let's start with the simplest possible network, that has inputs in the format
<code>7x8x8</code> and outputs move probabilities in a vector of size <code>64x64</code>.</p>
<p>We will have just one hidden layer of <code>N_HIDDEN</code> neurons in between the input and
output. The output will have a sigmoid activation applied on it, in order
to give us numbers between 0 and 1 which can be interpreted as probability
of a move.</p>
<p>(We're doing per move probability here. it is also possible to use softmax for
getting a probability distribution over all possible moves, but that makes the
learning harder. So just doing per-move probability for now.)</p>
<p><a href="https://github.com/krkartikay/chess-sl/blob/main/model.py">model.py</a></p>
<pre><code class="hljs language-py"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F

N_HIDDEN = <span class="hljs-number">64</span>*<span class="hljs-number">64</span>


<span class="hljs-keyword">class</span> <span class="hljs-title class_">ChessModel</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-built_in">super</span>(ChessModel, self).__init__()

        self.hidden_layer = nn.Linear(<span class="hljs-number">7</span>*<span class="hljs-number">8</span>*<span class="hljs-number">8</span>, N_HIDDEN)
        self.output_layer = nn.Linear(N_HIDDEN, <span class="hljs-number">64</span>*<span class="hljs-number">64</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):
        <span class="hljs-comment"># Flatten the tensor</span>
        x = x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)
        <span class="hljs-comment"># Apply hidden layer</span>
        x = self.hidden_layer(x)
        x = F.relu(x)
        <span class="hljs-comment"># Output layer</span>
        x = self.output_layer(x)
        x = F.sigmoid(x)
        <span class="hljs-keyword">return</span> x

</code></pre>
<h3>Training it!!!</h3>
<p>The most interesting part. Let's now load the data and train the neural net.</p>
<p><a href="https://github.com/krkartikay/chess-sl/blob/main/train.py">train.py</a></p>
<pre><code class="hljs language-py"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F

<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset, DataLoader
<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> SGD

<span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> ChessModel

BATCH_SIZE = <span class="hljs-number">256</span>
LEARNING_RATE = <span class="hljs-number">0.1</span>
NUM_EPOCHS = <span class="hljs-number">10</span>

<span class="hljs-built_in">print</span>(<span class="hljs-string">"Loading data..."</span>)

<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">"games.pth"</span>, <span class="hljs-string">"rb"</span>) <span class="hljs-keyword">as</span> datafile:
    data = torch.load(datafile)
    positions: torch.Tensor = data[<span class="hljs-string">"positions"</span>]
    valid_moves: torch.Tensor = data[<span class="hljs-string">"moves"</span>].<span class="hljs-built_in">float</span>()

<span class="hljs-built_in">print</span>(<span class="hljs-string">"Loaded data. Shape: "</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"positions : <span class="hljs-subst">{positions.size()}</span>"</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"moves     : <span class="hljs-subst">{valid_moves.size()}</span>"</span>)
<span class="hljs-built_in">print</span>()

chess_model = ChessModel()

dataset = TensorDataset(positions, valid_moves)
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=<span class="hljs-literal">True</span>)

sgd_optimizer = SGD(chess_model.parameters(), lr=LEARNING_RATE)

<span class="hljs-keyword">for</span> epochs <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(NUM_EPOCHS):
    <span class="hljs-keyword">for</span> positions, valid_moves <span class="hljs-keyword">in</span> dataloader:
        sgd_optimizer.zero_grad()

        move_probs = chess_model(positions)
        loss = F.binary_cross_entropy(move_probs, valid_moves)

        loss.backward()
        sgd_optimizer.step()
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Loss: <span class="hljs-subst">{loss.item():<span class="hljs-number">.4</span>f}</span>"</span>)

</code></pre>
<p>After adding a <a href="https://github.com/krkartikay/chess-sl/blob/677fb0146be77a1cfc8ee06944189b79cae4c1ac/train.py">bit more code</a>
for train-test dataset splitting and test evaluation, here is the output:</p>
<pre><code>(torch) krkartikay@KartikayLegion:~/code/chess-sl$ time python train.py 
Loading data...
Loaded data. Shape: 
positions : torch.Size([34511, 7, 8, 8])
moves     : torch.Size([34511, 4096])

1/  1, Loss: 0.6942
1/ 11, Loss: 0.6911
1/ 21, Loss: 0.6879
1/ 31, Loss: 0.6850
1/ 41, Loss: 0.6817
1/ 51, Loss: 0.6790
1/ 61, Loss: 0.6754
1/ 71, Loss: 0.6724
1/ 81, Loss: 0.6695
1/ 91, Loss: 0.6660
1/101, Loss: 0.6633
Epoch 1, Average Test Loss: 0.6601
2/  1, Loss: 0.6604
2/ 11, Loss: 0.6562
2/ 21, Loss: 0.6543
...
9/ 41, Loss: 0.1734
9/ 51, Loss: 0.1760
9/ 61, Loss: 0.2043
9/ 71, Loss: 0.1695
9/ 81, Loss: 0.1865
9/ 91, Loss: 0.1619
9/101, Loss: 0.1730
Epoch 9, Average Test Loss: 0.1667
10/  1, Loss: 0.1516
10/ 11, Loss: 0.1593
10/ 21, Loss: 0.1572
10/ 31, Loss: 0.1499
10/ 41, Loss: 0.1623
10/ 51, Loss: 0.1674
10/ 61, Loss: 0.1790
10/ 71, Loss: 0.1567
10/ 81, Loss: 0.1516
10/ 91, Loss: 0.1464
10/101, Loss: 0.1492
Epoch 10, Average Test Loss: 0.1475

real    1m46.265s
user    12m57.450s
sys     0m40.758s
</code></pre>
<p>It runs in about one minute on my PC. It kinda works for now. The loss is
decreasing, we've gotten a test loss of ~0.14. There's a lot more stuff left to
do, for example:</p>
<ul>
<li>Plotting the training and validation loss curves.</li>
<li>Evaluating the network by actually making it play chess.</li>
<li>Trying out different hyperparams and optimizers.</li>
<li>Optimising the network, decreasing the loss further.</li>
<li>Trying convolutional networks.</li>
</ul>
<p>(Link to code so far at <a href="https://github.com/krkartikay/chess-sl/tree/677fb0146be77a1cfc8ee06944189b79cae4c1ac">commit <code>677fb01</code></a>.)</p>
<p>I've made some progress on it locally but I'll update it here later. Getting too
late now... see ya!</p></div></div></div></main></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note_id":"machine learning__alpha zero__3-supervised-learning","noteData":{"metadata":{"title":"3. Supervised Learning","date":"2024-01-15"},"content":"\u003ch3\u003eFirst update!\u003c/h3\u003e\n\u003cp\u003eI've got supervised learning to kinda work!\u003c/p\u003e\n\u003cp\u003eI've been able to generate a dataset consisting of lots of random positions and\nthe allowed moves in all those positions. Then I've been able to read that data\nand train neural networks on it which learn the rules of chess reasonably well.\u003c/p\u003e\n\u003cp\u003eI'm implementing it again (cleanly) \u003ca href=\"https://github.com/krkartikay/chess-sl\"\u003ein this repo\u003c/a\u003e\nand also documenting whatever I'm doing here.\u003c/p\u003e\n\u003ch3\u003eGenerating the dataset\u003c/h3\u003e\n\u003cp\u003eFirst we will need to generate the dataset consisting of randomly generated\npositions and the allowed move in each position. This can be done using the\n\u003ccode\u003echess\u003c/code\u003e python library.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/krkartikay/chess-sl/blob/main/gen_moves.py\"\u003egen_moves.py\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e chess\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e random\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003egenerate_random_game\u003c/span\u003e():\n    board = chess.Board()\n    history = []\n    \u003cspan class=\"hljs-keyword\"\u003ewhile\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enot\u003c/span\u003e board.is_game_over():\n        \u003cspan class=\"hljs-comment\"\u003e# print(board)\u003c/span\u003e\n        valid_moves = \u003cspan class=\"hljs-built_in\"\u003elist\u003c/span\u003e(board.generate_legal_moves())\n        \u003cspan class=\"hljs-comment\"\u003e# print(valid_moves)\u003c/span\u003e\n        random_move = random.choice(valid_moves)\n        history.append((board, valid_moves))\n        board.push(random_move)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e history\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen we need to store the generated data. Now we could serialise it into any\nformat. Games are generally stored in PGN format and we could find some format\nfor our moves too but since we're going to train neural networks using this data\nso it may be best to convert these to tensors already and store them in a tensor\nformat.\u003c/p\u003e\n\u003cp\u003eSo far the code is pretty fast, taking only ~2s to generate 100 games.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ time python gen_moves.py \nGenerating game 1.\nGenerating game 2.\nGenerating game 3.\n...\nGenerating game 100.\nDone! Generated 100 games!\n\nreal    0m2.396s\nuser    0m2.282s\nsys     0m0.111s\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eConverting to tensors\u003c/h3\u003e\n\u003cp\u003eThere are many possible ways we could do this, but I'm going to encode the 6\npiece types (Pawn, Rook, Knight, etc.) into different planes into a tensor.\nI'm going to use +1 for the white pieces and -1 for the black pieces.\nI'm also going to add another plane which is entirely +1 or -1 denoting whose\nturn it is currently.\u003c/p\u003e\n\u003cp\u003eThis is what the starting board is supposed to look like, as a tensor (White = +1\nBlack = -1, Gray = 0).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/start-position.png\" alt=\"starting position tensor\"\u003e\u003c/p\u003e\n\u003cp\u003eHere's the code:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/krkartikay/chess-sl/blob/main/chess_utils.py\"\u003echess_utils.py\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e chess\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eboard_to_tensor\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eboard: chess.Board\u003c/span\u003e) -\u003e torch.Tensor:\n    return_tensor = torch.zeros((\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e))\n    \u003cspan class=\"hljs-comment\"\u003e# Iterate over the 6 piece types and add them to the appropriate plane\u003c/span\u003e\n    \u003cspan class=\"hljs-comment\"\u003e# in the return tensor.\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e layer \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e):\n        pt = chess.PieceType(layer)\n        \u003cspan class=\"hljs-comment\"\u003e# add +1 for all the white pieces and -1 for black pieces\u003c/span\u003e\n        bitboard_white = board.pieces_mask(pt, chess.WHITE)\n        bitboard_black = board.pieces_mask(pt, chess.BLACK)\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e sq \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e chess.SQUARES:\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e bitboard_white \u0026#x26; (\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u0026#x3C;\u0026#x3C; sq):\n                row, col = \u003cspan class=\"hljs-built_in\"\u003edivmod\u003c/span\u003e(sq, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e)\n                return_tensor[layer, row, col] += \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e bitboard_black \u0026#x26; (\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u0026#x3C;\u0026#x3C; sq):\n                row, col = \u003cspan class=\"hljs-built_in\"\u003edivmod\u003c/span\u003e(sq, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e)\n                return_tensor[layer, row, col] -= \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n        \u003cspan class=\"hljs-comment\"\u003e# fill in the last layer according with +/- 1 based on whose turn it is\u003c/span\u003e\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e board.turn == chess.WHITE:\n            return_tensor[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, :, :] += \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n        \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e:\n            return_tensor[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, :, :] -= \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e return_tensor\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSimply calling this function in \u003ccode\u003emain()\u003c/code\u003e on every position we have so far\nincreases the running time of the script to around ~5-6 seconds.\u003c/p\u003e\n\u003cp\u003eI'm also writing unit tests this time... it helped me catch a bug already!\n(Do you see what was wrong in the code above? Hehe...)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/krkartikay/chess-sl/blob/main/chess_utils_test.py\"\u003echess_utils_test.py\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e chess\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e chess_utils\n\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etest_board_to_tensor\u003c/span\u003e():\n    board = chess.Board()\n    tensor = chess_utils.board_to_tensor(board)\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(tensor)\n\n    \u003cspan class=\"hljs-comment\"\u003e# tensor has correct shape\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003eassert\u003c/span\u003e tensor.size() == (\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-comment\"\u003e# first turn is white\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003eassert\u003c/span\u003e tensor[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e] == \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n\n    \u003cspan class=\"hljs-comment\"\u003e# board has equal number of pieces at the start\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e):\n        \u003cspan class=\"hljs-keyword\"\u003eassert\u003c/span\u003e tensor[i].\u003cspan class=\"hljs-built_in\"\u003esum\u003c/span\u003e() == \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e$ pytest\n=========================== test session starts ============================\nplatform linux -- Python 3.11.4, pytest-7.4.0, pluggy-1.0.0\nrootdir: /home/krkartikay/code/chess-sl\nplugins: hydra-core-1.3.2, anyio-3.7.1\ncollected 1 item                                                           \n\nchess_utils_test.py F                                                [100%]\n\n================================= FAILURES =================================\n___________________________ test_board_to_tensor ___________________________\n\n    def test_board_to_tensor():\n        board = chess.Board()\n        tensor = chess_utils.board_to_tensor(board)\n    \n        # tensor has correct shape\n        assert tensor.size() == (7, 8, 8)\n    \n        # first turn is white\n\u003e       assert tensor[0, 0, 0] == 1\nE       assert tensor(6.) == 1\n\nchess_utils_test.py:13: AssertionError\n========================= short test summary info ==========================\nFAILED chess_utils_test.py::test_board_to_tensor - assert tensor(6.) == 1\n============================ 1 failed in 0.76s =============================\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eEncoding moves\u003c/h3\u003e\n\u003cp\u003eAnother big decision to make here is how to encode and decode the moves.\nAs I discussed last time, certain encodings make it easier or harder for the\nneural net to learn.\u003c/p\u003e\n\u003cp\u003eFor now I'm going to use a kind of \u003ccode\u003e(from sq, to sq)\u003c/code\u003e encoding.\u003c/p\u003e\n\u003cp\u003eHere are my conversion functions:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/krkartikay/chess-sl/blob/main/chess_utils.py\"\u003echess_utils.py\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003emove_to_action\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003emove: chess.Move\u003c/span\u003e) -\u003e \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e:\n    a = move.from_square\n    b = move.to_square\n    idx = (a * \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e) + b\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e idx\n\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eaction_to_move\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eaction: \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e, board: chess.Board\u003c/span\u003e) -\u003e chess.Move:\n    a, b = \u003cspan class=\"hljs-built_in\"\u003edivmod\u003c/span\u003e(action, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e)\n    move = chess.Move(a, b)\n\n    \u003cspan class=\"hljs-comment\"\u003e# check for possible promotion\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (chess.square_rank(b) == (\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e board.turn == chess.WHITE \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\n            \u003cspan class=\"hljs-keyword\"\u003eand\u003c/span\u003e board.piece_type_at(a) == chess.PAWN):\n        move = chess.Move(a, b, chess.QUEEN)\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e move\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTested these via round trip encoding-decoding unit tests. Promotion works but\nonly to queen. We're gonna be ignoring underpromotion for now. It'll complicate\nthe action space architecture.\u003c/p\u003e\n\u003cp\u003eOkay, now we just convert all the games to tensors and save them to a file.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003econvert_to_tensors\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003e\n        games: \u003cspan class=\"hljs-type\"\u003eList\u003c/span\u003e[\u003cspan class=\"hljs-type\"\u003eTuple\u003c/span\u003e[chess.Board, \u003cspan class=\"hljs-type\"\u003eList\u003c/span\u003e[chess.Move]]]\u003c/span\u003e) -\u003e torch.Tensor:\n    all_positions = []\n    all_valid_moves = []\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e game \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e games:\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e position, valid_moves \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e game:\n            board_tensor = board_to_tensor(position)\n            moves_tensor = moves_to_tensor(valid_moves)\n            all_positions.append(board_tensor)\n            all_valid_moves.append(moves_tensor)\n    positions = torch.stack(all_positions)\n    valid_moves = torch.stack(all_valid_moves)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e positions, valid_moves\n\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003esave_to_file\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003epositions, moves, filename=\u003cspan class=\"hljs-string\"\u003e'games.pth'\u003c/span\u003e\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(filename, \u003cspan class=\"hljs-string\"\u003e'wb'\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e datafile:\n        torch.save({\u003cspan class=\"hljs-string\"\u003e\"positions\"\u003c/span\u003e: positions, \u003cspan class=\"hljs-string\"\u003e\"moves\"\u003c/span\u003e: moves}, datafile)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd it works.  (Link to code so far at \u003ca href=\"https://github.com/krkartikay/chess-sl/tree/d5135642685c8b43e4ebd000319a94206cee2771\"\u003ecommit \u003ccode\u003ed513564\u003c/code\u003e\u003c/a\u003e.)\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ time python gen_moves.py \nGenerating game 1.\nGenerating game 2.\nGenerating game 3.\n...\nGenerating game 100.\nDone! Generated 100 games!\nConverting data to tensors.\nSaving to output file.\n\nreal    0m5.955s\nuser    0m5.743s\nsys     0m0.190s\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eCreating a neural net!\u003c/h3\u003e\n\u003cp\u003eLet's start with the simplest possible network, that has inputs in the format\n\u003ccode\u003e7x8x8\u003c/code\u003e and outputs move probabilities in a vector of size \u003ccode\u003e64x64\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eWe will have just one hidden layer of \u003ccode\u003eN_HIDDEN\u003c/code\u003e neurons in between the input and\noutput. The output will have a sigmoid activation applied on it, in order\nto give us numbers between 0 and 1 which can be interpreted as probability\nof a move.\u003c/p\u003e\n\u003cp\u003e(We're doing per move probability here. it is also possible to use softmax for\ngetting a probability distribution over all possible moves, but that makes the\nlearning harder. So just doing per-move probability for now.)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/krkartikay/chess-sl/blob/main/model.py\"\u003emodel.py\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch.nn \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e nn\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch.nn.functional \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e F\n\nN_HIDDEN = \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e\n\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eChessModel\u003c/span\u003e(nn.Module):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e(ChessModel, self).__init__()\n\n        self.hidden_layer = nn.Linear(\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, N_HIDDEN)\n        self.output_layer = nn.Linear(N_HIDDEN, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, x\u003c/span\u003e):\n        \u003cspan class=\"hljs-comment\"\u003e# Flatten the tensor\u003c/span\u003e\n        x = x.view(x.size(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e), -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n        \u003cspan class=\"hljs-comment\"\u003e# Apply hidden layer\u003c/span\u003e\n        x = self.hidden_layer(x)\n        x = F.relu(x)\n        \u003cspan class=\"hljs-comment\"\u003e# Output layer\u003c/span\u003e\n        x = self.output_layer(x)\n        x = F.sigmoid(x)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e x\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eTraining it!!!\u003c/h3\u003e\n\u003cp\u003eThe most interesting part. Let's now load the data and train the neural net.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/krkartikay/chess-sl/blob/main/train.py\"\u003etrain.py\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch.nn.functional \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e F\n\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.utils.data \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TensorDataset, DataLoader\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.optim \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SGD\n\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e model \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e ChessModel\n\nBATCH_SIZE = \u003cspan class=\"hljs-number\"\u003e256\u003c/span\u003e\nLEARNING_RATE = \u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e\nNUM_EPOCHS = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e\n\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Loading data...\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"games.pth\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"rb\"\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e datafile:\n    data = torch.load(datafile)\n    positions: torch.Tensor = data[\u003cspan class=\"hljs-string\"\u003e\"positions\"\u003c/span\u003e]\n    valid_moves: torch.Tensor = data[\u003cspan class=\"hljs-string\"\u003e\"moves\"\u003c/span\u003e].\u003cspan class=\"hljs-built_in\"\u003efloat\u003c/span\u003e()\n\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Loaded data. Shape: \"\u003c/span\u003e)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef\"positions : \u003cspan class=\"hljs-subst\"\u003e{positions.size()}\u003c/span\u003e\"\u003c/span\u003e)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef\"moves     : \u003cspan class=\"hljs-subst\"\u003e{valid_moves.size()}\u003c/span\u003e\"\u003c/span\u003e)\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e()\n\nchess_model = ChessModel()\n\ndataset = TensorDataset(positions, valid_moves)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\nsgd_optimizer = SGD(chess_model.parameters(), lr=LEARNING_RATE)\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e epochs \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(NUM_EPOCHS):\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e positions, valid_moves \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e dataloader:\n        sgd_optimizer.zero_grad()\n\n        move_probs = chess_model(positions)\n        loss = F.binary_cross_entropy(move_probs, valid_moves)\n\n        loss.backward()\n        sgd_optimizer.step()\n        \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef\"Loss: \u003cspan class=\"hljs-subst\"\u003e{loss.item():\u003cspan class=\"hljs-number\"\u003e.4\u003c/span\u003ef}\u003c/span\u003e\"\u003c/span\u003e)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter adding a \u003ca href=\"https://github.com/krkartikay/chess-sl/blob/677fb0146be77a1cfc8ee06944189b79cae4c1ac/train.py\"\u003ebit more code\u003c/a\u003e\nfor train-test dataset splitting and test evaluation, here is the output:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(torch) krkartikay@KartikayLegion:~/code/chess-sl$ time python train.py \nLoading data...\nLoaded data. Shape: \npositions : torch.Size([34511, 7, 8, 8])\nmoves     : torch.Size([34511, 4096])\n\n1/  1, Loss: 0.6942\n1/ 11, Loss: 0.6911\n1/ 21, Loss: 0.6879\n1/ 31, Loss: 0.6850\n1/ 41, Loss: 0.6817\n1/ 51, Loss: 0.6790\n1/ 61, Loss: 0.6754\n1/ 71, Loss: 0.6724\n1/ 81, Loss: 0.6695\n1/ 91, Loss: 0.6660\n1/101, Loss: 0.6633\nEpoch 1, Average Test Loss: 0.6601\n2/  1, Loss: 0.6604\n2/ 11, Loss: 0.6562\n2/ 21, Loss: 0.6543\n...\n9/ 41, Loss: 0.1734\n9/ 51, Loss: 0.1760\n9/ 61, Loss: 0.2043\n9/ 71, Loss: 0.1695\n9/ 81, Loss: 0.1865\n9/ 91, Loss: 0.1619\n9/101, Loss: 0.1730\nEpoch 9, Average Test Loss: 0.1667\n10/  1, Loss: 0.1516\n10/ 11, Loss: 0.1593\n10/ 21, Loss: 0.1572\n10/ 31, Loss: 0.1499\n10/ 41, Loss: 0.1623\n10/ 51, Loss: 0.1674\n10/ 61, Loss: 0.1790\n10/ 71, Loss: 0.1567\n10/ 81, Loss: 0.1516\n10/ 91, Loss: 0.1464\n10/101, Loss: 0.1492\nEpoch 10, Average Test Loss: 0.1475\n\nreal    1m46.265s\nuser    12m57.450s\nsys     0m40.758s\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIt runs in about one minute on my PC. It kinda works for now. The loss is\ndecreasing, we've gotten a test loss of ~0.14. There's a lot more stuff left to\ndo, for example:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePlotting the training and validation loss curves.\u003c/li\u003e\n\u003cli\u003eEvaluating the network by actually making it play chess.\u003c/li\u003e\n\u003cli\u003eTrying out different hyperparams and optimizers.\u003c/li\u003e\n\u003cli\u003eOptimising the network, decreasing the loss further.\u003c/li\u003e\n\u003cli\u003eTrying convolutional networks.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(Link to code so far at \u003ca href=\"https://github.com/krkartikay/chess-sl/tree/677fb0146be77a1cfc8ee06944189b79cae4c1ac\"\u003ecommit \u003ccode\u003e677fb01\u003c/code\u003e\u003c/a\u003e.)\u003c/p\u003e\n\u003cp\u003eI've made some progress on it locally but I'll update it here later. Getting too\nlate now... see ya!\u003c/p\u003e"},"allNotesIndex":{"base_name":"notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes","notes_data":[{"id":"quotes","metadata":{"title":"Quotes","date":"2023-03-21"}}],"directories":[{"base_name":"book notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes","notes_data":[{"id":"dokkodo","metadata":{"title":"Dokkodo","date":"2023-03-23"}},{"id":"if","metadata":{"title":"\"If\"","date":"2023-03-27"}},{"id":"worry","metadata":{"title":"Worry","date":"2023-03-29"}}],"directories":[{"base_name":"the bhagvad gita","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes/the bhagvad gita","notes_data":[{"id":"chapter_1","metadata":{"title":"Chapter 1","date":"2023-04-06"}},{"id":"chapter_2","metadata":{"title":"Chapter 2","date":"2023-04-08"}},{"id":"index","metadata":{"title":"The Bhagvad Gita","date":"2023-04-06"}}],"directories":[]}]},{"base_name":"economics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics","notes_data":[],"directories":[{"base_name":"microeconomics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics/microeconomics","notes_data":[{"id":"index","metadata":{"title":"Principles of Microeconomics","date":"2023-03-23"}},{"id":"lecture_1","metadata":{"title":"Lecture 1","date":"2023-03-23"}},{"id":"lecture_2","metadata":{"title":"Lecture 2","date":"2023-03-23"}},{"id":"lecture_3","metadata":{"title":"Lecture 3","date":"2023-03-23"}},{"id":"lecture_4","metadata":{"title":"Lecture 4","date":"2023-04-01"}},{"id":"lecture_5","metadata":{"title":"Lecture 5","date":"2023-04-01"}},{"id":"lecture_6","metadata":{"title":"Lecture 6","date":"2023-04-01"}}],"directories":[]}]},{"base_name":"machine learning","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning","notes_data":[{"id":"cpp-grad","metadata":{"title":"cpp-grad","date":"2023-04-17"}},{"id":"karpathy-lectures","metadata":{"title":"Andrey Karpathy's Lectures","date":"2023-05-14"}},{"id":"study-plan","metadata":{"title":"ML Study plan","date":"2024-01-14"}}],"directories":[{"base_name":"alpha zero","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning/alpha zero","notes_data":[{"id":"1-the-start","metadata":{"title":"1. The Start","date":"2024-01-14"}},{"id":"2-initial-plan","metadata":{"title":"2. Initial plan","date":"2024-01-14"}},{"id":"3-supervised-learning","metadata":{"title":"3. Supervised Learning","date":"2024-01-15"}},{"id":"4-experimentation","metadata":{"title":"4. Experimentation Framework","date":"2024-01-20"}},{"id":"5-visualization","metadata":{"title":"5. Visualization","date":"2024-01-21"}},{"id":"_notes","metadata":{"title":"_notes"}}],"directories":[]}]}]}},"__N_SSG":true},"page":"/notes/[note_id]","query":{"note_id":"machine learning__alpha zero__3-supervised-learning"},"buildId":"qT0P1lb5TYCjTWSp0uAq_","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>