<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>5. Visualization</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/584705cbbef33b49.css" as="style"/><link rel="stylesheet" href="/_next/static/css/584705cbbef33b49.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-83cebdb887f48834.js" defer=""></script><script src="/_next/static/chunks/pages/_app-eb98586f475796ed.js" defer=""></script><script src="/_next/static/chunks/247-fb3f3c148c859656.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bnote_id%5D-774c61eb2a4693cc.js" defer=""></script><script src="/_next/static/0cQi27foYwZlvrxIm4tXk/_buildManifest.js" defer=""></script><script src="/_next/static/0cQi27foYwZlvrxIm4tXk/_ssgManifest.js" defer=""></script></head><body class="dark:bg-black dark:bg-opacity-95"><div id="__next"><div><nav class="md:sticky md:top-0 md:z-40 shadow-sm p-2 bg-white dark:bg-black dark:shadow-lg dark:shadow-stone-800"><div class="flex items-center"><a class="flex" href="/"><img alt="Profile pic" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="rounded-full h-20 w-20 mx-2" style="color:transparent" src="/pfp_blank.png"/><h1 class="self-center text-xl text-stone-400 font-mono dark:text-stone-50 dark:drop-shadow-2xl dark:shadow-white dark:hover:text-stone-200">krkartikay&#x27;s notes</h1></a></div></nav><div class="flex flex-row flex-wrap"><aside class="md:w-1/4 text-stone-500 dark:text-stone-200"><div class="max-w-md mx-auto py-8"><a href="/"><h2 class="p-8 text-lg text-stone-600 hover:bg-stone-100 dark:text-stone-200 dark:hover:bg-stone-800 dark:hover:text-stone-200 ">Notes</h2></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Book Notes</li></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__if"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">&quot;If&quot;</li></a><a href="/notes/book%20notes__dokkodo"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Dokkodo</li></a><a href="/notes/book%20notes__the%20bhagvad%20gita__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">The Bhagvad Gita</li></a><ul class="list-disc pl-8"><a href="/notes/book%20notes__the%20bhagvad%20gita__chapter_1"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Chapter 1</li></a><a href="/notes/book%20notes__the%20bhagvad%20gita__chapter_2"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Chapter 2</li></a></ul><a href="/notes/book%20notes__worry"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Worry</li></a></ul><a href="/notes/economics__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Economics</li></a><ul class="list-disc pl-8"><a href="/notes/economics__microeconomics__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Microeconomics</li></a><ul class="list-disc pl-8"><a href="/notes/economics__microeconomics__lecture_1"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 1</li></a><a href="/notes/economics__microeconomics__lecture_2"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 2</li></a><a href="/notes/economics__microeconomics__lecture_3"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 3</li></a><a href="/notes/economics__microeconomics__lecture_4"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 4</li></a><a href="/notes/economics__microeconomics__lecture_5"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 5</li></a><a href="/notes/economics__microeconomics__lecture_6"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Lecture 6</li></a></ul></ul><a href="/notes/machine%20learning__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Machine Learning</li></a><ul class="list-disc pl-8"><a href="/notes/machine%20learning__alpha%20zero__index"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Alpha Zero</li></a><ul class="list-disc pl-8"><a href="/notes/machine%20learning__alpha%20zero__1-the-start"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">1. The Start</li></a><a href="/notes/machine%20learning__alpha%20zero__2-initial-plan"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">2. Initial plan</li></a><a href="/notes/machine%20learning__alpha%20zero__3-supervised-learning"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">3. Supervised Learning</li></a><a href="/notes/machine%20learning__alpha%20zero__4-experimentation"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">4. Experimentation Framework</li></a><a href="/notes/machine%20learning__alpha%20zero__5-visualization"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside font-bold bg-stone-50 dark:bg-stone-800">5. Visualization</li></a><a href="/notes/machine%20learning__alpha%20zero___notes"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">_notes</li></a></ul><a href="/notes/machine%20learning__karpathy-lectures"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Andrey Karpathy&#x27;s Lectures</li></a><a href="/notes/machine%20learning__study-plan"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">ML Study plan</li></a><a href="/notes/machine%20learning__cpp-grad"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">cpp-grad</li></a></ul><a href="/notes/quotes"><li class="py-2 pl-2 hover:bg-stone-100 hover:text-stone-600 dark:text-stone-400 dark:hover:bg-stone-800 dark:hover:text-stone-200 list-inside ">Quotes</li></a></ul></div></aside><main class="md:w-3/4 border-l-2 dark:border-l-stone-900 border-l-stone-50"><div class="p-8 md:p-16"><br/><h1 class="text-4xl dark:text-white">5. Visualization</h1><p class="text-stone-400 dark:text-stone-300">2024-01-21</p><div class="prose prose-stone dark:prose-invert"><div><h3>BUGS!!!</h3>
<p>I tried visualising the neural net outputs using matplotlib and I noticed the
training data was all wrong!!! There were two bugs:</p>
<ol>
<li>
<p>Board class is mutable... so when we ran <code>generate_random_game</code>, the board
state saved in <code>history</code> would be only a pointer to the current board. So
as the game progressed the history instead of looking like
<code>[(P0, M0), (P1, M1), ... (Pn, Mn)]</code> would look like
<code>[(Pn, M0), (Pn, M1), ... (Pn, Mn)]</code>.</p>
</li>
<li>
<p>In <code>chess_utils.py</code>, <code>moves_to_tensor</code>, I had assumed that <code>torch.BoolTensor</code>
would give me a tensor with all <code>False</code> in the beginning. That was incorrect,
it instead gives me a tensor filled with <code>True</code> and <code>False</code> randomly.
(Probably garbage values because we didn't initialise the buffer with
anything). So we had to use <code>torch.zeros</code> instead.</p>
</li>
</ol>
<p>Bug fixes:</p>
<pre><code class="hljs language-diff">  def generate_random_game() -> List[Tuple[chess.Board, List[chess.Move]]]:
      board = chess.Board()
      history = []
      while not board.is_game_over():
          # print(board)
          valid_moves = list(board.generate_legal_moves())
          # print(valid_moves)
          random_move = random.choice(valid_moves)
<span class="hljs-addition">+         history.append((chess.Board(board.fen()), valid_moves))</span>
<span class="hljs-deletion">-         history.append((board, valid_moves))</span>
          board.push(random_move)
      return history
</code></pre>
<pre><code class="hljs language-diff">  def moves_to_tensor(moves: List[chess.Move]) -> torch.Tensor:
<span class="hljs-addition">+     moves_tensor = torch.BoolTensor(64*64)</span>
<span class="hljs-deletion">-     moves_tensor = torch.zeros(64*64)</span>
      valid_actions = [move_to_action(move) for move in moves]
      moves_tensor[valid_actions] = 1
      return moves_tensor
</code></pre>
<p>After fixing these two bugs, the neural nets started training much better!</p>
<p>Before bug fix:</p>
<pre><code>run_num,OPTIMIZER,NUM_TRAINING_EXAMPLES,BATCH_SIZE,NUM_EPOCHS,LEARNING_RATE,final_train_loss,final_test_loss,running_time
1,ADAM,10000,128,20,1,0.0917012087764248,0.0948999347165227,9.442247152328491
</code></pre>
<p>After bug fix:</p>
<pre><code>run_num,OPTIMIZER,NUM_TRAINING_EXAMPLES,BATCH_SIZE,NUM_EPOCHS,LEARNING_RATE,final_train_loss,final_test_loss,running_time
1,ADAM,10000,128,20,1,0.010415336841510402,0.012209153734147549,9.533048629760742
</code></pre>
<p><img src="/notes/loss_after_data_fix.png" alt="loss plot after bug fix"></p>
<h3>Visualizations</h3>
<p>Ok, after training the network again let's now look at the visualizations again.
This is the code I used to visualise the networks:</p>
<pre><code class="hljs language-py"><span class="hljs-comment"># To plot the board tensor</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_pos_tensor</span>(<span class="hljs-params">tensor: torch.Tensor</span>):
    fig, axs = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">7</span>, figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">5</span>))
    channel_names = [<span class="hljs-string">'TURN'</span>, <span class="hljs-string">'PAWN'</span>, <span class="hljs-string">'KNIGHT'</span>, <span class="hljs-string">'BISHOP'</span>, <span class="hljs-string">'ROOK'</span>, <span class="hljs-string">'QUEEN'</span>, <span class="hljs-string">'KING'</span>]

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>):
        axs[i].imshow(tensor[i, :, :], cmap=<span class="hljs-string">'gray'</span>, vmin=-<span class="hljs-number">1</span>, vmax=<span class="hljs-number">1</span>, origin=<span class="hljs-string">"lower"</span>)
        axs[i].set_title(channel_names[i])

    plt.show()

<span class="hljs-comment"># To plot the moves tensor</span>
<span class="hljs-comment"># This will plot the moves tensor of length 4096 as a 64x64 image.</span>
<span class="hljs-comment"># The image can be thought of as a big chessboard with small chessboards on</span>
<span class="hljs-comment"># each square. The bigger square represents the start square and the smaller</span>
<span class="hljs-comment"># square represents the end square for each move.</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_move_set</span>(<span class="hljs-params">moves: torch.Tensor</span>):
    moves_view = torch.zeros(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>)
    <span class="hljs-keyword">for</span> start_row <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):
        <span class="hljs-keyword">for</span> start_col <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):
            <span class="hljs-keyword">for</span> end_row <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):
                <span class="hljs-keyword">for</span> end_col <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):
                    action_num = (start_row+start_col*<span class="hljs-number">8</span>)*<span class="hljs-number">64</span>+(end_row+end_col*<span class="hljs-number">8</span>)
                    moves_view[start_col*<span class="hljs-number">8</span>+end_col][start_row*<span class="hljs-number">8</span>+end_row] = moves[action_num]
    plt.imshow(moves_view, origin=<span class="hljs-string">"lower"</span>, vmin=<span class="hljs-number">0</span>, vmax=<span class="hljs-number">1</span>)
    plt.show()

<span class="hljs-comment"># To plot the top k moves as arrows on an svg chess board</span>
<span class="hljs-comment"># (use in jupyter notebooks)</span>
<span class="hljs-comment"># The opacity of the arrow is proportional to the move probability.</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_board_moves</span>(<span class="hljs-params">board: chess.Board, probs: torch.Tensor, k=<span class="hljs-number">20</span></span>):
    arrows = []
    probs, actions = torch.topk(probs, k)
    <span class="hljs-keyword">for</span> prob, action <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(probs, actions):
        arrow_color = <span class="hljs-string">f"#009900<span class="hljs-subst">{<span class="hljs-built_in">int</span>(prob*<span class="hljs-number">128</span>):02x}</span>"</span>
        move = action_to_move(action.item(), board)
        <span class="hljs-built_in">print</span>(move, prob)
        arrows.append(chess.svg.Arrow(move.from_square, move.to_square, color=arrow_color))
    <span class="hljs-keyword">return</span> chess.svg.board(board, arrows=arrows)
</code></pre>
<h4>Start position</h4>
<p>Here's what the start position looks like:</p>
<p><img src="/notes/start-position.png" alt="start position tensor with 7 planes"></p>
<p>And here is a representation of the valid moves of the start position:</p>
<p><img src="/notes/start-moves.png" alt="valid moves image for start position"></p>
<p>Note that this is a 64x64 image and it can be thought of as a big chessboard
with small chessboards on each square. The bigger square represents the start
square and the smaller square represents the end square for each move.</p>
<p>We can see the pawns having 2 moves each and the knights also having 2 possible
moves each in the starting position. All other pieces are blocked.</p>
<h4>Position 1</h4>
<p>Let's look at a certain random position. It's Black's turn to play.</p>
<p><img src="/notes/board-position-141.svg" alt="board at position 141"></p>
<p><img src="/notes/random-position-141.png" alt="board tensor for position 141"></p>
<p>This should be the correct answer for the possible moves:</p>
<p><img src="/notes/moves-position-141.png" alt="valid moves position 141"></p>
<p>And if we plot what the neural network outputs, this is what we get (the
predicted probabilities for the possible moves):</p>
<p><img src="/notes/moves-predicted-141.png" alt="predicted moves position 141"></p>
<p>Here's how it looks like represented on a chessboard with arrows. (The opacity
of the arrow is proportional to move probability.)</p>
<p><img src="/notes/board-moves-predicted-141.svg" alt="predicted moves with arrows position 141"></p>
<p>We can see its mostly correctly predicting the moves for the queen and bishop,
although it's still predicting a bit of probability for the black bishop going past
the white bishop. It's also struggling a bit to predict the rook moves which are totally
valid (not sure why) but there is still some probability predicted for those.
Also the black king shouldn't be able to move anywhere (check), and the net
definitely is showing low probabilities for those moves.</p>
<p>So the net definitely understands some sort of concept that the king can't move
into check.</p>
<h4>Position 2</h4>
<p>Here's another slightly trickier position. This time it's tricky to predict
the right moves because the king is in check and there is really only one
move that is valid in this position (bishop to d2 to block the check).</p>
<p><img src="/notes/board-position-142.svg" alt="board at position 142"></p>
<p>Board tensor:</p>
<p><img src="/notes/random-position-142.png" alt="board tensor for position 142"></p>
<p>Valid moves (only one pixel is ON):</p>
<p><img src="/notes/moves-position-142.png" alt="valid moves position 142"></p>
<p>This is what the neural net predicts:</p>
<p><img src="/notes/moves-predicted-142.png" alt="predicted moves position 142"></p>
<p><img src="/notes/board-moves-predicted-142.svg" alt="predicted moves with arrows position 142"></p>
<p>Here are the raw probabilities for each move:</p>
<pre><code>c3c4 tensor(0.6879)
e3d2 tensor(0.6831)
e5f6 tensor(0.6757)
d4d3 tensor(0.6654)
h5h6 tensor(0.6511)
h1h3 tensor(0.6164)
h1h2 tensor(0.5898)
h1h4 tensor(0.4512)
e3f4 tensor(0.3785)
e3f2 tensor(0.3347)
</code></pre>
<p>The correct move is e3d2, it has the second highest probability. However the
net is still struggling to understand this position (as I would have expected).
It is only a single layer net so far, probably more layers would be required
to understand how to detect (and block) checks. The first layer can possibly
detect valid moves, it takes one more step to detect checks, and yet one more
step to realise that we are in check and we need to block it.</p>
<p>Anyway, I've committed the code so far at <a href="https://github.com/krkartikay/chess-sl/tree/a7f6106b7257a0ccb28a48624b76e0413b9b0b24">commit <code>a7f6106</code></a>. Make sure to check out
the visualisations in the <a href="https://github.com/krkartikay/chess-sl/blob/a7f6106b7257a0ccb28a48624b76e0413b9b0b24/visualizations.ipynb">jupyter notebook!</a>.</p>
<p>Okay so what next? Next I'll try to develop an evaluation framework to
(a) test the network by 'live' play and measure number of moves played,
(b) measure metrics like precision/recall
(c) Try more neural net architectures to drive those metrics up!</p></div></div></div></main></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note_id":"machine learning__alpha zero__5-visualization","noteData":{"metadata":{"title":"5. Visualization","date":"2024-01-21"},"content":"\u003ch3\u003eBUGS!!!\u003c/h3\u003e\n\u003cp\u003eI tried visualising the neural net outputs using matplotlib and I noticed the\ntraining data was all wrong!!! There were two bugs:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eBoard class is mutable... so when we ran \u003ccode\u003egenerate_random_game\u003c/code\u003e, the board\nstate saved in \u003ccode\u003ehistory\u003c/code\u003e would be only a pointer to the current board. So\nas the game progressed the history instead of looking like\n\u003ccode\u003e[(P0, M0), (P1, M1), ... (Pn, Mn)]\u003c/code\u003e would look like\n\u003ccode\u003e[(Pn, M0), (Pn, M1), ... (Pn, Mn)]\u003c/code\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIn \u003ccode\u003echess_utils.py\u003c/code\u003e, \u003ccode\u003emoves_to_tensor\u003c/code\u003e, I had assumed that \u003ccode\u003etorch.BoolTensor\u003c/code\u003e\nwould give me a tensor with all \u003ccode\u003eFalse\u003c/code\u003e in the beginning. That was incorrect,\nit instead gives me a tensor filled with \u003ccode\u003eTrue\u003c/code\u003e and \u003ccode\u003eFalse\u003c/code\u003e randomly.\n(Probably garbage values because we didn't initialise the buffer with\nanything). So we had to use \u003ccode\u003etorch.zeros\u003c/code\u003e instead.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBug fixes:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e  def generate_random_game() -\u003e List[Tuple[chess.Board, List[chess.Move]]]:\n      board = chess.Board()\n      history = []\n      while not board.is_game_over():\n          # print(board)\n          valid_moves = list(board.generate_legal_moves())\n          # print(valid_moves)\n          random_move = random.choice(valid_moves)\n\u003cspan class=\"hljs-addition\"\u003e+         history.append((chess.Board(board.fen()), valid_moves))\u003c/span\u003e\n\u003cspan class=\"hljs-deletion\"\u003e-         history.append((board, valid_moves))\u003c/span\u003e\n          board.push(random_move)\n      return history\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e  def moves_to_tensor(moves: List[chess.Move]) -\u003e torch.Tensor:\n\u003cspan class=\"hljs-addition\"\u003e+     moves_tensor = torch.BoolTensor(64*64)\u003c/span\u003e\n\u003cspan class=\"hljs-deletion\"\u003e-     moves_tensor = torch.zeros(64*64)\u003c/span\u003e\n      valid_actions = [move_to_action(move) for move in moves]\n      moves_tensor[valid_actions] = 1\n      return moves_tensor\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter fixing these two bugs, the neural nets started training much better!\u003c/p\u003e\n\u003cp\u003eBefore bug fix:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003erun_num,OPTIMIZER,NUM_TRAINING_EXAMPLES,BATCH_SIZE,NUM_EPOCHS,LEARNING_RATE,final_train_loss,final_test_loss,running_time\n1,ADAM,10000,128,20,1,0.0917012087764248,0.0948999347165227,9.442247152328491\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter bug fix:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003erun_num,OPTIMIZER,NUM_TRAINING_EXAMPLES,BATCH_SIZE,NUM_EPOCHS,LEARNING_RATE,final_train_loss,final_test_loss,running_time\n1,ADAM,10000,128,20,1,0.010415336841510402,0.012209153734147549,9.533048629760742\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/notes/loss_after_data_fix.png\" alt=\"loss plot after bug fix\"\u003e\u003c/p\u003e\n\u003ch3\u003eVisualizations\u003c/h3\u003e\n\u003cp\u003eOk, after training the network again let's now look at the visualizations again.\nThis is the code I used to visualise the networks:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-py\"\u003e\u003cspan class=\"hljs-comment\"\u003e# To plot the board tensor\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eplot_pos_tensor\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003etensor: torch.Tensor\u003c/span\u003e):\n    fig, axs = plt.subplots(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e, figsize=(\u003cspan class=\"hljs-number\"\u003e15\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e))\n    channel_names = [\u003cspan class=\"hljs-string\"\u003e'TURN'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'PAWN'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'KNIGHT'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'BISHOP'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'ROOK'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'QUEEN'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'KING'\u003c/span\u003e]\n\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e):\n        axs[i].imshow(tensor[i, :, :], cmap=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e, vmin=-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, vmax=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, origin=\u003cspan class=\"hljs-string\"\u003e\"lower\"\u003c/span\u003e)\n        axs[i].set_title(channel_names[i])\n\n    plt.show()\n\n\u003cspan class=\"hljs-comment\"\u003e# To plot the moves tensor\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# This will plot the moves tensor of length 4096 as a 64x64 image.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# The image can be thought of as a big chessboard with small chessboards on\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# each square. The bigger square represents the start square and the smaller\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# square represents the end square for each move.\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eplot_move_set\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003emoves: torch.Tensor\u003c/span\u003e):\n    moves_view = torch.zeros(\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e start_row \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e):\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e start_col \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e):\n            \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e end_row \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e):\n                \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e end_col \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e):\n                    action_num = (start_row+start_col*\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e)*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e+(end_row+end_col*\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e)\n                    moves_view[start_col*\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e+end_col][start_row*\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e+end_row] = moves[action_num]\n    plt.imshow(moves_view, origin=\u003cspan class=\"hljs-string\"\u003e\"lower\"\u003c/span\u003e, vmin=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, vmax=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n    plt.show()\n\n\u003cspan class=\"hljs-comment\"\u003e# To plot the top k moves as arrows on an svg chess board\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# (use in jupyter notebooks)\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# The opacity of the arrow is proportional to the move probability.\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eplot_board_moves\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eboard: chess.Board, probs: torch.Tensor, k=\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e\u003c/span\u003e):\n    arrows = []\n    probs, actions = torch.topk(probs, k)\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e prob, action \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003ezip\u003c/span\u003e(probs, actions):\n        arrow_color = \u003cspan class=\"hljs-string\"\u003ef\"#009900\u003cspan class=\"hljs-subst\"\u003e{\u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e(prob*\u003cspan class=\"hljs-number\"\u003e128\u003c/span\u003e):02x}\u003c/span\u003e\"\u003c/span\u003e\n        move = action_to_move(action.item(), board)\n        \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(move, prob)\n        arrows.append(chess.svg.Arrow(move.from_square, move.to_square, color=arrow_color))\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e chess.svg.board(board, arrows=arrows)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eStart position\u003c/h4\u003e\n\u003cp\u003eHere's what the start position looks like:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/start-position.png\" alt=\"start position tensor with 7 planes\"\u003e\u003c/p\u003e\n\u003cp\u003eAnd here is a representation of the valid moves of the start position:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/start-moves.png\" alt=\"valid moves image for start position\"\u003e\u003c/p\u003e\n\u003cp\u003eNote that this is a 64x64 image and it can be thought of as a big chessboard\nwith small chessboards on each square. The bigger square represents the start\nsquare and the smaller square represents the end square for each move.\u003c/p\u003e\n\u003cp\u003eWe can see the pawns having 2 moves each and the knights also having 2 possible\nmoves each in the starting position. All other pieces are blocked.\u003c/p\u003e\n\u003ch4\u003ePosition 1\u003c/h4\u003e\n\u003cp\u003eLet's look at a certain random position. It's Black's turn to play.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/board-position-141.svg\" alt=\"board at position 141\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/random-position-141.png\" alt=\"board tensor for position 141\"\u003e\u003c/p\u003e\n\u003cp\u003eThis should be the correct answer for the possible moves:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/moves-position-141.png\" alt=\"valid moves position 141\"\u003e\u003c/p\u003e\n\u003cp\u003eAnd if we plot what the neural network outputs, this is what we get (the\npredicted probabilities for the possible moves):\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/moves-predicted-141.png\" alt=\"predicted moves position 141\"\u003e\u003c/p\u003e\n\u003cp\u003eHere's how it looks like represented on a chessboard with arrows. (The opacity\nof the arrow is proportional to move probability.)\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/board-moves-predicted-141.svg\" alt=\"predicted moves with arrows position 141\"\u003e\u003c/p\u003e\n\u003cp\u003eWe can see its mostly correctly predicting the moves for the queen and bishop,\nalthough it's still predicting a bit of probability for the black bishop going past\nthe white bishop. It's also struggling a bit to predict the rook moves which are totally\nvalid (not sure why) but there is still some probability predicted for those.\nAlso the black king shouldn't be able to move anywhere (check), and the net\ndefinitely is showing low probabilities for those moves.\u003c/p\u003e\n\u003cp\u003eSo the net definitely understands some sort of concept that the king can't move\ninto check.\u003c/p\u003e\n\u003ch4\u003ePosition 2\u003c/h4\u003e\n\u003cp\u003eHere's another slightly trickier position. This time it's tricky to predict\nthe right moves because the king is in check and there is really only one\nmove that is valid in this position (bishop to d2 to block the check).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/board-position-142.svg\" alt=\"board at position 142\"\u003e\u003c/p\u003e\n\u003cp\u003eBoard tensor:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/random-position-142.png\" alt=\"board tensor for position 142\"\u003e\u003c/p\u003e\n\u003cp\u003eValid moves (only one pixel is ON):\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/moves-position-142.png\" alt=\"valid moves position 142\"\u003e\u003c/p\u003e\n\u003cp\u003eThis is what the neural net predicts:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/moves-predicted-142.png\" alt=\"predicted moves position 142\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/notes/board-moves-predicted-142.svg\" alt=\"predicted moves with arrows position 142\"\u003e\u003c/p\u003e\n\u003cp\u003eHere are the raw probabilities for each move:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ec3c4 tensor(0.6879)\ne3d2 tensor(0.6831)\ne5f6 tensor(0.6757)\nd4d3 tensor(0.6654)\nh5h6 tensor(0.6511)\nh1h3 tensor(0.6164)\nh1h2 tensor(0.5898)\nh1h4 tensor(0.4512)\ne3f4 tensor(0.3785)\ne3f2 tensor(0.3347)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe correct move is e3d2, it has the second highest probability. However the\nnet is still struggling to understand this position (as I would have expected).\nIt is only a single layer net so far, probably more layers would be required\nto understand how to detect (and block) checks. The first layer can possibly\ndetect valid moves, it takes one more step to detect checks, and yet one more\nstep to realise that we are in check and we need to block it.\u003c/p\u003e\n\u003cp\u003eAnyway, I've committed the code so far at \u003ca href=\"https://github.com/krkartikay/chess-sl/tree/a7f6106b7257a0ccb28a48624b76e0413b9b0b24\"\u003ecommit \u003ccode\u003ea7f6106\u003c/code\u003e\u003c/a\u003e. Make sure to check out\nthe visualisations in the \u003ca href=\"https://github.com/krkartikay/chess-sl/blob/a7f6106b7257a0ccb28a48624b76e0413b9b0b24/visualizations.ipynb\"\u003ejupyter notebook!\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOkay so what next? Next I'll try to develop an evaluation framework to\n(a) test the network by 'live' play and measure number of moves played,\n(b) measure metrics like precision/recall\n(c) Try more neural net architectures to drive those metrics up!\u003c/p\u003e"},"allNotesIndex":{"base_name":"notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes","notes_data":[{"id":"quotes","metadata":{"title":"Quotes","date":"2023-03-21"}}],"directories":[{"base_name":"book notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes","notes_data":[{"id":"dokkodo","metadata":{"title":"Dokkodo","date":"2023-03-23"}},{"id":"if","metadata":{"title":"\"If\"","date":"2023-03-27"}},{"id":"worry","metadata":{"title":"Worry","date":"2023-03-29"}}],"directories":[{"base_name":"the bhagvad gita","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes/the bhagvad gita","notes_data":[{"id":"chapter_1","metadata":{"title":"Chapter 1","date":"2023-04-06"}},{"id":"chapter_2","metadata":{"title":"Chapter 2","date":"2023-04-08"}},{"id":"index","metadata":{"title":"The Bhagvad Gita","date":"2023-04-06"}}],"directories":[]}]},{"base_name":"economics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics","notes_data":[],"directories":[{"base_name":"microeconomics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics/microeconomics","notes_data":[{"id":"index","metadata":{"title":"Principles of Microeconomics","date":"2023-03-23"}},{"id":"lecture_1","metadata":{"title":"Lecture 1","date":"2023-03-23"}},{"id":"lecture_2","metadata":{"title":"Lecture 2","date":"2023-03-23"}},{"id":"lecture_3","metadata":{"title":"Lecture 3","date":"2023-03-23"}},{"id":"lecture_4","metadata":{"title":"Lecture 4","date":"2023-04-01"}},{"id":"lecture_5","metadata":{"title":"Lecture 5","date":"2023-04-01"}},{"id":"lecture_6","metadata":{"title":"Lecture 6","date":"2023-04-01"}}],"directories":[]}]},{"base_name":"machine learning","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning","notes_data":[{"id":"cpp-grad","metadata":{"title":"cpp-grad","date":"2023-04-17"}},{"id":"karpathy-lectures","metadata":{"title":"Andrey Karpathy's Lectures","date":"2023-05-14"}},{"id":"study-plan","metadata":{"title":"ML Study plan","date":"2024-01-14"}}],"directories":[{"base_name":"alpha zero","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning/alpha zero","notes_data":[{"id":"1-the-start","metadata":{"title":"1. The Start","date":"2024-01-14"}},{"id":"2-initial-plan","metadata":{"title":"2. Initial plan","date":"2024-01-14"}},{"id":"3-supervised-learning","metadata":{"title":"3. Supervised Learning","date":"2024-01-15"}},{"id":"4-experimentation","metadata":{"title":"4. Experimentation Framework","date":"2024-01-20"}},{"id":"5-visualization","metadata":{"title":"5. Visualization","date":"2024-01-21"}},{"id":"_notes","metadata":{"title":"_notes"}}],"directories":[]}]}]}},"__N_SSG":true},"page":"/notes/[note_id]","query":{"note_id":"machine learning__alpha zero__5-visualization"},"buildId":"0cQi27foYwZlvrxIm4tXk","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>