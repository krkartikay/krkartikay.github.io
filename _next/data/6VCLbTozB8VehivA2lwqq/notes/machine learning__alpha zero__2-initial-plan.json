{"pageProps":{"note_id":"machine learning__alpha zero__2-initial-plan","noteData":{"metadata":{"title":"2. Initial plan","date":"2024-01-14"},"content":"<h2>Initial Plan</h2>\n<p>Let's create a new repository... <a href=\"https://github.com/krkartikay/chess-sl\">done</a>!</p>\n<p>Okay here's the plan. We'll start with doing supervised learning only.\nThat too on self-generated data. Once we have a neural net that has\nat least learnt <em>the rules of chess</em> we'll go ahead and try reinforcement\nlearning using MCTS.</p>\n<ol>\n<li>Create a new repository.</li>\n<li>Install pytorch etc., whatever is required.</li>\n<li>Create the most basic supervised learning model possible.</li>\n<li>Create an experimentation framework.</li>\n<li>Create a framework for visualisation of the model and data.</li>\n</ol>\n<p>The real question is... How?</p>\n<p>What do I mean by experimentation and observability framework?</p>\n<p>A few ideas:</p>\n<ol>\n<li>imagine I have a dashboard where I can adjust hyperparams,\nclick buttons to start/stop training runs, it shows graphs etc.</li>\n<li>imagine I have a config file where I can specify a few\ndifferent values of hyperparameters and the thing runs\nexperiments in the background and stores the results\nin appropriate files (which we can compare in the above dashboard later)</li>\n<li>imagine I have a tool to analyse the training data and the\nmodel's output distributions on an actual chessboard visualisation.\nLike drawing arrows on the chessboard, showing probs, etc.</li>\n</ol>\n<p>From previous experience, it would be better to develop different tools in a modular way.</p>\n<p>So we could go about it in this order:</p>\n<ol>\n<li>Python framework to run the experiments and store results.</li>\n<li>Dashboard to visualise results.</li>\n<li>Dashboard to control hyperparams and run training scripts.</li>\n<li>Dashboard for chess data and model analysis.</li>\n</ol>\n<p>Once (1) is done, it would be much easier to develop the dashboards (2) and (3)!\nWe could use something standard like Sqlite for (1) and maybe flask or streamlit or something\nfor (2) and (3). (4) is a bit uncertain, but probably the best way to go about it\nwould be starting with llichess's chess board modules.</p>\n<h2>Problem specification</h2>\n<p>There are some choices we need to make while modeling the problem itself.\nWhat exactly is it that we're trying to do first?</p>\n<p>I was trying last time to just get a neural net to <em>learn the rules of chess</em>,\nthat is, by being shown a lot of games, just predict which moves are allowed and which ones\nare not.</p>\n<p>I just realised last night that this task can become much more simpler for the neural net\ndepending on the action space encoding.</p>\n<p>In particular what I was trying to do last time was to make the network predict the probability\ndistribution of valid moves, with the action space being <code>(from square, to square)</code>, that is,\n<code>64*64</code> actions.</p>\n<p>However I realised most of the neurons which would have to predict the probabilities\nwould ideally have to always output <code>0</code>. Why? Because for every <code>from square</code>, only certain\n<code>to squares</code> could ever be valid moves.</p>\n<p>In particular, for every <code>from</code> square we would have an upper bound of\n<code>8(hz) + 8(vt) + 8(dg)(max) + 8(dg)(max) + 8(kn)(max) = 40</code> possible <code>to</code>\nsquares. That means the real size of the action space should be closer to\n<code>40*64=2560</code> instead of <code>64*64=4096</code> (not considering underpromotions).</p>\n<p>Also Leela Chess Zero has an action space size of <code>1858</code> which they say\nthey gather from an <code>73*8*8</code> matrix using a certain mapping. Where did\nthey get <code>1858</code> from!?</p>\n<p>Anyway, back to the original question. Let's actually try to do the same thing as last time.\nWe'll predict the <code>64*64</code> probabilities for <code>(from square, to square)</code>.\n(We'll ignore underpromotion for now).</p>\n<p>(*note to myself: keep in mind bugs related to underpromotion and castling.)</p>\n<p>This would be a real test of <em>generalisation</em>. Is our network able to learn\n<em>the rules of chess</em> or does it simply memorise the training data?</p>\n<h3>Output?</h3>\n<p>What should the model output?</p>\n<p>Last time I used KL-divergence loss to make the net predict a probability distribution for\nall the moves, but I wonder if a per-move probability is better. In one experiment I had\nfound that a per-move probability is probably much easier to train as there is no dependence on\nother moves. However should it really be this way? TODO: think about this more later.</p>\n<p>For now let's make it do the latter. That is, we will have 64*64 per-move probabilities.\n(ideally many of which should always be 0 after training).</p>\n<h3>Let's go!</h3>\n<p>Okay we're all set for now, LESGOOO!</p>"},"allNotesIndex":{"base_name":"notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes","notes_data":[{"id":"quotes","metadata":{"title":"Quotes","date":"2023-03-21"}}],"directories":[{"base_name":"book notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes","notes_data":[{"id":"dokkodo","metadata":{"title":"Dokkodo","date":"2023-03-23"}},{"id":"if","metadata":{"title":"\"If\"","date":"2023-03-27"}},{"id":"worry","metadata":{"title":"Worry","date":"2023-03-29"}}],"directories":[{"base_name":"the bhagvad gita","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes/the bhagvad gita","notes_data":[{"id":"chapter_1","metadata":{"title":"Chapter 1","date":"2023-04-06"}},{"id":"chapter_2","metadata":{"title":"Chapter 2","date":"2023-04-08"}},{"id":"index","metadata":{"title":"The Bhagvad Gita","date":"2023-04-06"}}],"directories":[]}]},{"base_name":"economics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics","notes_data":[],"directories":[{"base_name":"microeconomics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics/microeconomics","notes_data":[{"id":"index","metadata":{"title":"Principles of Microeconomics","date":"2023-03-23"}},{"id":"lecture_1","metadata":{"title":"Lecture 1","date":"2023-03-23"}},{"id":"lecture_2","metadata":{"title":"Lecture 2","date":"2023-03-23"}},{"id":"lecture_3","metadata":{"title":"Lecture 3","date":"2023-03-23"}},{"id":"lecture_4","metadata":{"title":"Lecture 4","date":"2023-04-01"}},{"id":"lecture_5","metadata":{"title":"Lecture 5","date":"2023-04-01"}},{"id":"lecture_6","metadata":{"title":"Lecture 6","date":"2023-04-01"}}],"directories":[]}]},{"base_name":"machine learning","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning","notes_data":[{"id":"cpp-grad","metadata":{"title":"cpp-grad","date":"2023-04-17"}},{"id":"karpathy-lectures","metadata":{"title":"Andrey Karpathy's Lectures","date":"2023-05-14"}},{"id":"study-plan","metadata":{"title":"ML Study plan","date":"2024-01-14"}}],"directories":[{"base_name":"alpha zero","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning/alpha zero","notes_data":[{"id":"1-the-start","metadata":{"title":"1. The Start","date":"2024-01-14"}},{"id":"2-initial-plan","metadata":{"title":"2. Initial plan","date":"2024-01-14"}},{"id":"_notes","metadata":{"title":"_notes"}}],"directories":[]}]}]}},"__N_SSG":true}