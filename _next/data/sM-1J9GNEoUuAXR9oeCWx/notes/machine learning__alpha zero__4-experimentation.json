{"pageProps":{"note_id":"machine learning__alpha zero__4-experimentation","noteData":{"metadata":{"title":"4. Experimentation Framework","date":"2024-01-20"},"content":"<h3>Running the model on GPU</h3>\n<p>Ok, we had left off with training the model on our small dataset of 100 games\nfor 10 epochs. It was taking ~1 min on my machine to run it. However I noticed\nlater that it was so slow because it was training on CPU!</p>\n<p>To train it on the GPU, we only need a small change.</p>\n<pre><code class=\"hljs language-diff\"><span class=\"hljs-deletion\">- chess_model = ChessModel()</span>\n<span class=\"hljs-addition\">+ # Transfer data to GPU if available</span>\n<span class=\"hljs-addition\">+ device = 'cuda' if torch.cuda.is_available() else 'cpu'</span>\n<span class=\"hljs-addition\">+ </span>\n<span class=\"hljs-addition\">+ positions = positions.to(device)</span>\n<span class=\"hljs-addition\">+ valid_moves = valid_moves.to(device)</span>\n<span class=\"hljs-addition\">+ </span>\n<span class=\"hljs-addition\">+ # Create the neural net</span>\n<span class=\"hljs-addition\">+ chess_model = ChessModel().to(device)</span>\n</code></pre>\n<p>The <code>.to(device)</code> function transfers data to the GPU in pytorch and the whole\ncomputation works on the GPU after that.</p>\n<pre><code>(torch) krkartikay@KartikayLegion:~/code/chess-sl$ time python train.py \n...\nEpoch 10, Average Test Loss: 0.1468\n\nreal    0m6.975s\nuser    0m6.034s\nsys     0m1.003s\n</code></pre>\n<p>Now it's only taking ~7sec to train the model. That's almost a 10x improvement!</p>\n<p>However, an important point to be noted here is that this is working only\nbecause our dataset is small enough to fit in the VRAM of the GPU in one go.\nIf the dataset did not fit in the VRAM either of two things would happen:</p>\n<ol>\n<li>Either the CUDA drivers fail with an out of memory error! (best-case scenario), or,</li>\n<li>The training keeps running using our RAM ('shared memory') instead, but runs much more\nslowly and without any warnings.</li>\n</ol>\n<p>In the second case we might think everything is running fine but actually there\nwould be an issue, and everything might be <em>much</em> slower than it can be.\nUnfortunately (2) is the default behaviour of the CUDA drivers these days, but\nthat can be changed in the settings (later...).</p>\n<p>The proper solution would really be to stream the data to the GPU per-batch, or\npossibly even stream the data from disk to RAM (and from RAM to GPU) in a\nmultithreaded dataloader, in case the dataset is big enough to not fit in RAM.</p>\n<p>However let's implement that later and focus on experimenting with the network\nfor now.</p>\n<h3>Optimising the network</h3>\n<p>We could now try out various things to optimise the network but keeping track of\nhow various hyperparams are affecting the quality of the network is hard if we\ndo it manually.</p>\n<p>So we'll now develop a framework to keep track of the configs and run\nexperiments by changing them systematically and noting the results.</p>\n<h3>Observations</h3>\n<p>The most important thing while doing experiments is to keep track of\nobservations!</p>\n<p>There's a risk of overengineering this part... For instance there are entire\nteams at google which handle metric collection and monitoring. But I'll try to\nkeep things simple here.</p>\n<p>Let's create an observer class which we can call <code>observer.record(variable)</code> on.\nIt will help us record and store the data.</p>\n<p><a href=\"https://github.com/krkartikay/chess-sl/blob/main/observer.py\">observer.py</a>:</p>\n<pre><code class=\"hljs language-py\"><span class=\"hljs-comment\"># Observation framework</span>\n\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> csv\n<span class=\"hljs-keyword\">import</span> pickle\n<span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Observer</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, name, path=<span class=\"hljs-string\">\"\"</span>, suffix=<span class=\"hljs-string\">\"\"</span></span>):\n        self.name = name\n        self.suffix = suffix\n        self.fullname = os.path.join(\n            path, name + (<span class=\"hljs-string\">f\"_<span class=\"hljs-subst\">{suffix}</span>\"</span> <span class=\"hljs-keyword\">if</span> suffix <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"\"</span>))\n        self.observations = []\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">record</span>(<span class=\"hljs-params\">self, variable</span>):\n        self.observations.append(variable)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">write_csv</span>(<span class=\"hljs-params\">self</span>):\n        filename = (<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.fullname}</span>.csv\"</span>)\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(self.observations) == <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-keyword\">return</span>\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(filename, <span class=\"hljs-string\">\"w\"</span>) <span class=\"hljs-keyword\">as</span> file_handle:\n            csv_writer = csv.writer(file_handle)\n            csv_writer.writerows([x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> self.observations)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">save_pkl</span>(<span class=\"hljs-params\">self</span>):\n        filename = (<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.fullname}</span>.pkl\"</span>)\n        pickle.dump(self.observations, <span class=\"hljs-built_in\">open</span>(filename, <span class=\"hljs-string\">\"wb\"</span>))\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">plot</span>(<span class=\"hljs-params\">self</span>):\n        filename = (<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.fullname}</span>.png\"</span>)\n        plt.figure()\n        plt.plot(self.observations)\n        plt.savefig(filename)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">avg</span>(<span class=\"hljs-params\">self</span>):\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">sum</span>(self.observations) / <span class=\"hljs-built_in\">len</span>(self.observations)\n\n</code></pre>\n<p>To be honest it's nothing more than an array with some functions to save it,\nplot it, etc.</p>\n<p>Let's see if we can plot the training and test loss with it now. (I've modified\nthe code a little bit to handle calling <code>record</code> on tuples/lists, and also\nincreased the epochs to 50.)</p>\n<p>Relevant part of <code>train.py</code> now:</p>\n<pre><code class=\"hljs language-py\">sgd_optimizer = SGD(chess_model.parameters(), lr=LEARNING_RATE)\n\nloss_observer = Observer(<span class=\"hljs-string\">'loss'</span>, path=<span class=\"hljs-string\">\"results/\"</span>)\n\n<span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(NUM_EPOCHS):\n    <span class=\"hljs-keyword\">for</span> batch_num, (train_positions, train_valid_moves) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_dataloader):\n        sgd_optimizer.zero_grad()\n\n        move_probs = chess_model(train_positions)\n        loss = F.binary_cross_entropy(move_probs, train_valid_moves)\n\n        loss.backward()\n        sgd_optimizer.step()\n\n        <span class=\"hljs-keyword\">if</span> batch_num % <span class=\"hljs-number\">10</span> == <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{epoch+<span class=\"hljs-number\">1</span>}</span>/<span class=\"hljs-subst\">{batch_num+<span class=\"hljs-number\">1</span>:3d}</span>, Loss: <span class=\"hljs-subst\">{loss.item():<span class=\"hljs-number\">.4</span>f}</span>\"</span>)\n\n    <span class=\"hljs-comment\"># Test Evaluation</span>\n    chess_model.<span class=\"hljs-built_in\">eval</span>()\n\n    total_test_loss = <span class=\"hljs-number\">0</span>\n    <span class=\"hljs-keyword\">with</span> torch.no_grad():\n        <span class=\"hljs-keyword\">for</span> test_positions, test_valid_moves <span class=\"hljs-keyword\">in</span> test_dataloader:\n            test_move_probs = chess_model(test_positions)\n            test_loss = F.binary_cross_entropy(\n                test_move_probs, test_valid_moves)\n            total_test_loss += test_loss.item()\n\n    last_training_loss = loss.item()\n    average_test_loss = total_test_loss / <span class=\"hljs-built_in\">len</span>(test_dataloader)\n    loss_observer.record((last_training_loss, average_test_loss))\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Epoch <span class=\"hljs-subst\">{epoch+<span class=\"hljs-number\">1</span>}</span>, Average Test Loss: <span class=\"hljs-subst\">{average_test_loss:<span class=\"hljs-number\">.4</span>f}</span>\"</span>)\n\nloss_observer.plot([<span class=\"hljs-string\">'train_loss'</span>, <span class=\"hljs-string\">'test_loss'</span>])\nloss_observer.write_csv()\n</code></pre>\n<p>(Link to code so far at <a href=\"https://github.com/krkartikay/chess-sl/tree/09820da5afdac68cbdd3cbefe0a449cf81dccce3\">commit <code>09820da</code></a>.)</p>\n<p>Training Output:</p>\n<pre><code>(torch) krkartikay@KartikayLegion:~/code/chess-sl$ time python train.py \nLoading data...\nLoaded data. Shape: \npositions : torch.Size([34879, 7, 8, 8])\nmoves     : torch.Size([34879, 4096])\n\n1/  1, Loss: 0.6941\n1/ 11, Loss: 0.6910\n1/ 21, Loss: 0.6880\n...\n50/ 91, Loss: 0.1098\n50/101, Loss: 0.1038\nEpoch 50, Average Test Loss: 0.1048\n\nreal    0m23.212s\nuser    0m21.790s\nsys     0m1.442\n</code></pre>\n<p><code>results/loss.png</code> and <code>results/loss.csv</code> were created successfully.</p>\n<p><code>loss.csv</code>:</p>\n<pre><code>train_loss,test_loss\n0.6621306538581848,0.6606337598391941\n0.6188064217567444,0.6185613402298519\n0.557918906211853,0.5588848718575069\n...\n</code></pre>\n<p><code>loss.png</code>: <img src=\"/notes/loss-plot-1.png\" alt=\"loss plot\"></p>\n<h3>Experimentation framework</h3>\n<p>We need to optimise the neural net further! I think the loss of ~0.1 we're\ngetting now is still too high. We could bring it down further by tweaking\nhyperparams and perhaps model architecture but let's develop a proper\nframework first to run experiments.</p>\n<p>I want to be able to do something like this:</p>\n<pre><code class=\"hljs language-py\">----------------------------------------------------------------------\nconfig.py:\n\nBATCH_SIZE = Config(default=<span class=\"hljs-number\">128</span>, values=[<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">512</span>])\nNUM_EPOCHS = Config(default=<span class=\"hljs-number\">100</span>, dev=<span class=\"hljs-number\">10</span>)\nLEARNING_RATE = Config(default=<span class=\"hljs-number\">0.1</span>, values=[<span class=\"hljs-number\">0.01</span>, <span class=\"hljs-number\">0.03</span>, <span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">10</span>])\n----------------------------------------------------------------------\nmain.py:\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run_training</span>():\n    train_model()\n\nrun_experiment(variables=[BATCH_SIZE, LEARNING_RATE],\n               function=run_training,\n               time_limit=<span class=\"hljs-string\">\"5 mins\"</span>)\n\n----------------------------------------------------------------------\ntrain.py:\n\n<span class=\"hljs-keyword\">from</span> config <span class=\"hljs-keyword\">import</span> NUM_EPOCHS, LEARNING_RATE, BATCH_SIZE\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">train_model</span>():\n    ...\n    optim = SGD(model.parameters(), learning_rate=LEARNING_RATE.get())\n    \n    <span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(NUM_EPOCHS.get()):\n        ...\n\n----------------------------------------------------------------------\n</code></pre>\n<p>That is, I specify all possible values of my hyperparameters and\n<code>run_experiment</code> basically tries out all the possible combinations of the\nvariables I specify and stores all the results. So that I could see what the\neffect of each variable is on the training, and also find out the optimal values\nof hyperparameters which are giving me the best loss. I also want it to have a\n<code>dev</code> mode where it runs experiments on a smaller scale which I can use to test\nmy code before doing a full training run.</p>\n<p>Okay... implemented this... here's some of the relevant parts of the code:</p>\n<pre><code class=\"hljs language-py\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Experiment</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, variables=[], dev_mode=<span class=\"hljs-literal\">False</span></span>):\n        self.variables: <span class=\"hljs-type\">List</span>[Config] = variables\n        self.dev_mode: <span class=\"hljs-built_in\">bool</span> = dev_mode\n        ...\n        self.run_number: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">0</span>\n        self.selected_values: <span class=\"hljs-type\">Dict</span>[Config, <span class=\"hljs-type\">Any</span>] = {}\n        self.all_configs_results: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">Any</span>] = {}\n        <span class=\"hljs-keyword\">for</span> config <span class=\"hljs-keyword\">in</span> ALL_CONFIGS:\n            config.expt = self\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_config</span>(<span class=\"hljs-params\">self, config</span>):\n        <span class=\"hljs-keyword\">if</span> config <span class=\"hljs-keyword\">in</span> self.selected_values:\n            <span class=\"hljs-keyword\">return</span> self.selected_values[config]\n        <span class=\"hljs-keyword\">elif</span> self.dev_mode:\n            <span class=\"hljs-keyword\">return</span> config.dev\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-keyword\">return</span> config.default\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run_experiment</span>(<span class=\"hljs-params\">self,\n                       function=<span class=\"hljs-literal\">None</span>,\n                       time_limit: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">0</span></span>):\n        value_combinations = itertools.product(\n            *[v.values <span class=\"hljs-keyword\">for</span> v <span class=\"hljs-keyword\">in</span> self.variables])\n        <span class=\"hljs-keyword\">for</span> values <span class=\"hljs-keyword\">in</span> value_combinations:\n            self.run_experiment_with_values(function, values)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run_experiment_with_values</span>(<span class=\"hljs-params\">self, function, values</span>):\n        self.selected_values = {\n            self.variables[i].name: values[i]\n            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(self.variables))}\n        <span class=\"hljs-comment\"># run_experiment will run this function with selected values of</span>\n        <span class=\"hljs-comment\"># variables</span>\n        self.run_number += <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-built_in\">print</span>()\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"===================================================\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Experiment run <span class=\"hljs-subst\">{self.run_number}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"---------------------------------------------------\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Config for this run:\\n<span class=\"hljs-subst\">{self.selected_values}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"===================================================\"</span>)\n        start_time = time.time()\n        results = function()\n        end_time = time.time()\n        time_taken = end_time - start_time\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"===================================================\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Run finished in <span class=\"hljs-subst\">{time_taken:<span class=\"hljs-number\">3.2</span>f}</span>sec.\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"===================================================\"</span>)\n        <span class=\"hljs-built_in\">print</span>()\n        self.all_configs_results.append({<span class=\"hljs-string\">'run_num'</span>: self.run_number})\n        <span class=\"hljs-keyword\">for</span> key, value <span class=\"hljs-keyword\">in</span> self.selected_values.items():\n            self.all_configs_results[-<span class=\"hljs-number\">1</span>][key] = value\n        <span class=\"hljs-keyword\">for</span> key, value <span class=\"hljs-keyword\">in</span> results.items():\n            self.all_configs_results[-<span class=\"hljs-number\">1</span>][key] = value\n        self.all_configs_results[-<span class=\"hljs-number\">1</span>][<span class=\"hljs-string\">'running_time'</span>] = time_taken\n        <span class=\"hljs-keyword\">for</span> obs <span class=\"hljs-keyword\">in</span> ALL_OBSERVERS:\n            obs.set_path(path=self.results_path,\n                         suffix=<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.run_number:03d}</span>\"</span>)\n            obs.plot()\n            obs.write_csv()\n        self.save_results()\n</code></pre>\n<p>Link to the full code at <a href=\"https://github.com/krkartikay/chess-sl/tree/1547c2a2d19a4b557eb044688467daca2c57c12b\">commit <code>1547c2a</code></a>.</p>\n<p>It's not really the best code I've written... I'm sure the design isn't as good\nas it could have been... but at least it works.</p>\n<p>Here's what the results look like:</p>\n<p><img src=\"/notes/experiment-results-1.png\" alt=\"experiment results csv and loss graph\"></p>\n<h3>Analysing the results</h3>\n<p>Loading up the <code>results.csv</code> in excel and applying conditional formatting for\neasier visualisation, here's what I get:</p>\n<p><img src=\"/notes/experiment-results-2.png\" alt=\"experiment results spreadsheet\"></p>\n<p>What're the main conclusions we can draw from this data? The main things I can\nnotice are:</p>\n<ul>\n<li>Lower batch sizes take longer to compute (obvious)</li>\n<li>Smaller batch sizes train faster (lower loss even with low LR)</li>\n<li>Larger batch sizes requiring higher LR to converge (gradient competition?)</li>\n<li>Theoretically I would've guessed lower batch sizes to overfit more easily,\nand it kinda looks like it's going in that direction in run #6 &#x26; #7, train loss\nbecoming slightly lower than test loss... (although I need to run it for\nmore epochs to confirm this...)</li>\n<li>Conversely larger batch sizes should've generalised a bit more (run #20?)</li>\n<li>Final loss is around ~0.1-0.09 in all cases.</li>\n</ul>\n<p>That's it for now. Next time we can try:</p>\n<ul>\n<li>Improve neural net architecture: adding conv layers etc.</li>\n<li>Evaluate the model by making it play games?</li>\n<li>More training data</li>\n<li>Visualisations...</li>\n</ul>"},"allNotesIndex":{"base_name":"notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes","notes_data":[{"id":"quotes","metadata":{"title":"Quotes","date":"2023-03-21"}}],"directories":[{"base_name":"book notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes","notes_data":[{"id":"dokkodo","metadata":{"title":"Dokkodo","date":"2023-03-23"}},{"id":"if","metadata":{"title":"\"If\"","date":"2023-03-27"}},{"id":"worry","metadata":{"title":"Worry","date":"2023-03-29"}}],"directories":[{"base_name":"the bhagvad gita","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes/the bhagvad gita","notes_data":[{"id":"chapter_1","metadata":{"title":"Chapter 1","date":"2023-04-06"}},{"id":"chapter_2","metadata":{"title":"Chapter 2","date":"2023-04-08"}},{"id":"index","metadata":{"title":"The Bhagvad Gita","date":"2023-04-06"}}],"directories":[]}]},{"base_name":"economics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics","notes_data":[],"directories":[{"base_name":"microeconomics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics/microeconomics","notes_data":[{"id":"index","metadata":{"title":"Principles of Microeconomics","date":"2023-03-23"}},{"id":"lecture_1","metadata":{"title":"Lecture 1","date":"2023-03-23"}},{"id":"lecture_2","metadata":{"title":"Lecture 2","date":"2023-03-23"}},{"id":"lecture_3","metadata":{"title":"Lecture 3","date":"2023-03-23"}},{"id":"lecture_4","metadata":{"title":"Lecture 4","date":"2023-04-01"}},{"id":"lecture_5","metadata":{"title":"Lecture 5","date":"2023-04-01"}},{"id":"lecture_6","metadata":{"title":"Lecture 6","date":"2023-04-01"}}],"directories":[]}]},{"base_name":"machine learning","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning","notes_data":[{"id":"cpp-grad","metadata":{"title":"cpp-grad","date":"2023-04-17"}},{"id":"karpathy-lectures","metadata":{"title":"Andrey Karpathy's Lectures","date":"2023-05-14"}},{"id":"study-plan","metadata":{"title":"ML Study plan","date":"2024-01-14"}}],"directories":[{"base_name":"alpha zero","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning/alpha zero","notes_data":[{"id":"1-the-start","metadata":{"title":"1. The Start","date":"2024-01-14"}},{"id":"2-initial-plan","metadata":{"title":"2. Initial plan","date":"2024-01-14"}},{"id":"3-supervised-learning","metadata":{"title":"3. Supervised Learning","date":"2024-01-15"}},{"id":"4-experimentation","metadata":{"title":"4. Experimentation Framework","date":"2024-01-20"}},{"id":"5-visualization","metadata":{"title":"5. Visualization","date":"2024-01-21"}},{"id":"_notes","metadata":{"title":"_notes"}}],"directories":[]}]}]}},"__N_SSG":true}