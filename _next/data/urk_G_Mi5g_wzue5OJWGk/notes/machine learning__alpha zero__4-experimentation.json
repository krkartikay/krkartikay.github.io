{"pageProps":{"note_id":"machine learning__alpha zero__4-experimentation","noteData":{"metadata":{"title":"4. Experimentation Framework","date":"2024-01-20"},"content":"<h3>Running the model on GPU</h3>\n<p>Ok, we had left off with training the model on our small dataset of 100 games\nfor 10 epochs. It was taking ~1 min on my machine to run it. However I noticed\nlater that it was so slow because it was training on CPU!</p>\n<p>To train it on the GPU, we only need a small change.</p>\n<pre><code class=\"hljs language-diff\"><span class=\"hljs-deletion\">- chess_model = ChessModel()</span>\n<span class=\"hljs-addition\">+ # Transfer data to GPU if available</span>\n<span class=\"hljs-addition\">+ device = 'cuda' if torch.cuda.is_available() else 'cpu'</span>\n<span class=\"hljs-addition\">+ </span>\n<span class=\"hljs-addition\">+ positions = positions.to(device)</span>\n<span class=\"hljs-addition\">+ valid_moves = valid_moves.to(device)</span>\n<span class=\"hljs-addition\">+ </span>\n<span class=\"hljs-addition\">+ # Create the neural net</span>\n<span class=\"hljs-addition\">+ chess_model = ChessModel().to(device)</span>\n</code></pre>\n<p>The <code>.to(device)</code> function transfers data to the GPU in pytorch and the whole\ncomputation works on the GPU after that.</p>\n<pre><code>(torch) krkartikay@KartikayLegion:~/code/chess-sl$ time python train.py \n...\nEpoch 10, Average Test Loss: 0.1468\n\nreal    0m6.975s\nuser    0m6.034s\nsys     0m1.003s\n</code></pre>\n<p>Now it's only taking ~7sec to train the model. That's almost a 10x improvement!</p>\n<p>However, an important point to be noted here is that this is working only\nbecause our dataset is small enough to fit in the VRAM of the GPU in one go.\nIf the dataset did not fit in the VRAM either of two things would happen:</p>\n<ol>\n<li>Either the CUDA drivers fail with an out of memory error! (best-case scenario), or,</li>\n<li>The training keeps running using our RAM ('shared memory') instead, but runs much more\nslowly and without any warnings.</li>\n</ol>\n<p>In the second case we might think everything is running fine but actually there\nwould be an issue, and everything might be <em>much</em> slower than it can be.\nUnfortunately (2) is the default behaviour of the CUDA drivers these days, but\nthat can be changed in the settings (later...).</p>\n<p>The proper solution would really be to stream the data to the GPU per-batch, or\npossibly even stream the data from disk to RAM (and from RAM to GPU) in a\nmultithreaded dataloader, in case the dataset is big enough to not fit in RAM.</p>\n<p>However let's implement that later and focus on experimenting with the network\nfor now.</p>\n<h3>Optimising the network</h3>\n<p>We could now try out various things to optimise the network but keeping track of\nhow various hyperparams are affecting the quality of the network is hard if we\ndo it manually.</p>\n<p>So we'll now develop a framework to keep track of the configs and run\nexperiments by changing them systematically and noting the results.</p>\n<h3>Observations</h3>\n<p>The most important thing while doing experiments is to keep track of\nobservations!</p>\n<p>There's a risk of overengineering this part... For instance there are entire\nteams at google which handle metric collection and monitoring. But I'll try to\nkeep things simple here.</p>\n<p>Let's create an observer class which we can call <code>observer.record(variable)</code> on.\nIt will help us record and store the data.</p>\n<p><a href=\"https://github.com/krkartikay/chess-sl/blob/main/observer.py\">observer.py</a>:</p>\n<pre><code class=\"hljs language-py\"><span class=\"hljs-comment\"># Observation framework</span>\n\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> csv\n<span class=\"hljs-keyword\">import</span> pickle\n<span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Observer</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, name, path=<span class=\"hljs-string\">\"\"</span>, suffix=<span class=\"hljs-string\">\"\"</span></span>):\n        self.name = name\n        self.suffix = suffix\n        self.fullname = os.path.join(\n            path, name + (<span class=\"hljs-string\">f\"_<span class=\"hljs-subst\">{suffix}</span>\"</span> <span class=\"hljs-keyword\">if</span> suffix <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"\"</span>))\n        self.observations = []\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">record</span>(<span class=\"hljs-params\">self, variable</span>):\n        self.observations.append(variable)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">write_csv</span>(<span class=\"hljs-params\">self</span>):\n        filename = (<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.fullname}</span>.csv\"</span>)\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(self.observations) == <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-keyword\">return</span>\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(filename, <span class=\"hljs-string\">\"w\"</span>) <span class=\"hljs-keyword\">as</span> file_handle:\n            csv_writer = csv.writer(file_handle)\n            csv_writer.writerows([x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> self.observations)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">save_pkl</span>(<span class=\"hljs-params\">self</span>):\n        filename = (<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.fullname}</span>.pkl\"</span>)\n        pickle.dump(self.observations, <span class=\"hljs-built_in\">open</span>(filename, <span class=\"hljs-string\">\"wb\"</span>))\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">plot</span>(<span class=\"hljs-params\">self</span>):\n        filename = (<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.fullname}</span>.png\"</span>)\n        plt.figure()\n        plt.plot(self.observations)\n        plt.savefig(filename)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">avg</span>(<span class=\"hljs-params\">self</span>):\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">sum</span>(self.observations) / <span class=\"hljs-built_in\">len</span>(self.observations)\n\n</code></pre>\n<p>To be honest it's nothing more than an array with some functions to save it,\nplot it, etc.</p>\n<p>Let's see if we can plot the training and test loss with it now. (I've modified\nthe code a little bit to handle calling <code>record</code> on tuples/lists, and also\nincreased the epochs to 50.)</p>\n<p>Relevant part of <code>train.py</code> now:</p>\n<pre><code class=\"hljs language-py\">sgd_optimizer = SGD(chess_model.parameters(), lr=LEARNING_RATE)\n\nloss_observer = Observer(<span class=\"hljs-string\">'loss'</span>, path=<span class=\"hljs-string\">\"results/\"</span>)\n\n<span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(NUM_EPOCHS):\n    <span class=\"hljs-keyword\">for</span> batch_num, (train_positions, train_valid_moves) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(train_dataloader):\n        sgd_optimizer.zero_grad()\n\n        move_probs = chess_model(train_positions)\n        loss = F.binary_cross_entropy(move_probs, train_valid_moves)\n\n        loss.backward()\n        sgd_optimizer.step()\n\n        <span class=\"hljs-keyword\">if</span> batch_num % <span class=\"hljs-number\">10</span> == <span class=\"hljs-number\">0</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{epoch+<span class=\"hljs-number\">1</span>}</span>/<span class=\"hljs-subst\">{batch_num+<span class=\"hljs-number\">1</span>:3d}</span>, Loss: <span class=\"hljs-subst\">{loss.item():<span class=\"hljs-number\">.4</span>f}</span>\"</span>)\n\n    <span class=\"hljs-comment\"># Test Evaluation</span>\n    chess_model.<span class=\"hljs-built_in\">eval</span>()\n\n    total_test_loss = <span class=\"hljs-number\">0</span>\n    <span class=\"hljs-keyword\">with</span> torch.no_grad():\n        <span class=\"hljs-keyword\">for</span> test_positions, test_valid_moves <span class=\"hljs-keyword\">in</span> test_dataloader:\n            test_move_probs = chess_model(test_positions)\n            test_loss = F.binary_cross_entropy(\n                test_move_probs, test_valid_moves)\n            total_test_loss += test_loss.item()\n\n    last_training_loss = loss.item()\n    average_test_loss = total_test_loss / <span class=\"hljs-built_in\">len</span>(test_dataloader)\n    loss_observer.record((last_training_loss, average_test_loss))\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Epoch <span class=\"hljs-subst\">{epoch+<span class=\"hljs-number\">1</span>}</span>, Average Test Loss: <span class=\"hljs-subst\">{average_test_loss:<span class=\"hljs-number\">.4</span>f}</span>\"</span>)\n\nloss_observer.plot([<span class=\"hljs-string\">'train_loss'</span>, <span class=\"hljs-string\">'test_loss'</span>])\nloss_observer.write_csv()\n</code></pre>\n<p>Training Output:</p>\n<pre><code>(torch) krkartikay@KartikayLegion:~/code/chess-sl$ time python train.py \nLoading data...\nLoaded data. Shape: \npositions : torch.Size([34879, 7, 8, 8])\nmoves     : torch.Size([34879, 4096])\n\n1/  1, Loss: 0.6941\n1/ 11, Loss: 0.6910\n1/ 21, Loss: 0.6880\n...\n50/ 91, Loss: 0.1098\n50/101, Loss: 0.1038\nEpoch 50, Average Test Loss: 0.1048\n\nreal    0m23.212s\nuser    0m21.790s\nsys     0m1.442\n</code></pre>\n<p><code>results/loss.png</code> and <code>results/loss.csv</code> were created successfully.</p>\n<p><code>loss.png</code>: <img src=\"/notes/loss-plot-1.png\" alt=\"loss plot\"></p>\n<p><code>loss.csv</code>:</p>\n<pre><code>train_loss,test_loss\n0.6621306538581848,0.6606337598391941\n0.6188064217567444,0.6185613402298519\n0.557918906211853,0.5588848718575069\n...\n</code></pre>\n<p>(Link to code so far at <a href=\"https://github.com/krkartikay/chess-sl/tree/6407403ea4519041087cd44952b7f165de0917d4\">commit <code>6407403</code></a>.)</p>"},"allNotesIndex":{"base_name":"notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes","notes_data":[{"id":"quotes","metadata":{"title":"Quotes","date":"2023-03-21"}}],"directories":[{"base_name":"book notes","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes","notes_data":[{"id":"dokkodo","metadata":{"title":"Dokkodo","date":"2023-03-23"}},{"id":"if","metadata":{"title":"\"If\"","date":"2023-03-27"}},{"id":"worry","metadata":{"title":"Worry","date":"2023-03-29"}}],"directories":[{"base_name":"the bhagvad gita","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/book notes/the bhagvad gita","notes_data":[{"id":"chapter_1","metadata":{"title":"Chapter 1","date":"2023-04-06"}},{"id":"chapter_2","metadata":{"title":"Chapter 2","date":"2023-04-08"}},{"id":"index","metadata":{"title":"The Bhagvad Gita","date":"2023-04-06"}}],"directories":[]}]},{"base_name":"economics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics","notes_data":[],"directories":[{"base_name":"microeconomics","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/economics/microeconomics","notes_data":[{"id":"index","metadata":{"title":"Principles of Microeconomics","date":"2023-03-23"}},{"id":"lecture_1","metadata":{"title":"Lecture 1","date":"2023-03-23"}},{"id":"lecture_2","metadata":{"title":"Lecture 2","date":"2023-03-23"}},{"id":"lecture_3","metadata":{"title":"Lecture 3","date":"2023-03-23"}},{"id":"lecture_4","metadata":{"title":"Lecture 4","date":"2023-04-01"}},{"id":"lecture_5","metadata":{"title":"Lecture 5","date":"2023-04-01"}},{"id":"lecture_6","metadata":{"title":"Lecture 6","date":"2023-04-01"}}],"directories":[]}]},{"base_name":"machine learning","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning","notes_data":[{"id":"cpp-grad","metadata":{"title":"cpp-grad","date":"2023-04-17"}},{"id":"karpathy-lectures","metadata":{"title":"Andrey Karpathy's Lectures","date":"2023-05-14"}},{"id":"study-plan","metadata":{"title":"ML Study plan","date":"2024-01-14"}}],"directories":[{"base_name":"alpha zero","full_path":"/home/runner/work/krkartikay.github.io/krkartikay.github.io/notes/machine learning/alpha zero","notes_data":[{"id":"1-the-start","metadata":{"title":"1. The Start","date":"2024-01-14"}},{"id":"2-initial-plan","metadata":{"title":"2. Initial plan","date":"2024-01-14"}},{"id":"3-supervised-learning","metadata":{"title":"3. Supervised Learning","date":"2024-01-15"}},{"id":"4-experimentation","metadata":{"title":"4. Experimentation Framework","date":"2024-01-20"}},{"id":"_notes","metadata":{"title":"_notes"}}],"directories":[]}]}]}},"__N_SSG":true}